[{"categories":["System"],"content":"Clash for Windows Clash for Window工具是基于Clash开发的，服务于Windows、macOS平台的网络代理工具。其主要提供添加、使用及订阅代理等服务。 Clash\"\rClash\r 快速下载：Clash.for.Windows 0.15.10 Setup ","date":"2021-06-29","objectID":"/posts/software_collection/:1:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"Listary Listary是一款实用的搜索工具，其主要为Windows提供快速打开指定目录/文件的实用功能，能极大提高日常工作效率。 Listary\"\rListary\r 快速下载：Listary 6.0.5.16 Setup ","date":"2021-06-29","objectID":"/posts/software_collection/:2:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"Snipaste Snipaste是一个简单但强大的截图工具，Beta版本为免费版本。 Snipaste\"\rSnipaste\r 快速下载：Snipaste x64 2.4.0 Portable ","date":"2021-06-29","objectID":"/posts/software_collection/:3:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"PowerToys PowerToys是微软为Windows推出的一款小巧的系统增强工具，开源且免费，功能也非常实用。 PowerToys\"\rPowerToys\r FancyZones是其中的一个分屏功能，可以根据需要对窗口进行完美的分屏，不再局限于左右式的分屏。 快速下载：PowerToys 0.41.3 Setup ","date":"2021-06-29","objectID":"/posts/software_collection/:4:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"IDM Internet Download Manager下载器中文破解版是一个十分好用的文件下载工具。IDM并不是一款免费的软件，但可通过淘宝，以较低的价格购买到注册码。 IDM\"\rIDM\r 快速下载：IDM 6.38 Setup ","date":"2021-06-29","objectID":"/posts/software_collection/:5:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"Uninstall Tool Uninstall Tool是一款功能强大的专业卸载工具。它比Windows自带的“添加/删除程序”功能快3倍! Uninstall Tool\"\rUninstall Tool\r 它可移除系统自带程序功能所不能删除的程序，使用强制删除可卸载注册表相关项，支持显示隐藏的安装程序，按名称过滤已安装程序列表，强行卸载程序，浏览注册表项目，保存安装程序列表，软件小巧，操作简便。 快速下载：Uninstall Tool x64 3.5.10 Setup/Portable ","date":"2021-06-29","objectID":"/posts/software_collection/:6:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"Potplayer PotPlayer是一款备受好评的电脑端本地视频播放器，它界面简洁，无广告，加载速度快，且功能强大，支持目前市面上几乎所有的视频播放格式。 Potplayer\"\rPotplayer\r 快速下载：Potplayer x64 Setup ","date":"2021-06-29","objectID":"/posts/software_collection/:7:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"Apowersoft SRP Apowersoft Screen Recorder Pro是一款小巧的录屏软件，自带视频编辑软件，可以将视频快捷转换为各种格式，包括GIF格式。 Apowersoft Screen Recorder Pro\"\rApowersoft Screen Recorder Pro\r 快速下载：Apowersoft Screen Recorder Pro 2.4.1.9 ","date":"2021-06-29","objectID":"/posts/software_collection/:8:0","tags":["Efficiency"],"title":"Software Collection","uri":"/posts/software_collection/"},{"categories":["System"],"content":"高效搜索 使用Windows系统的用户，对于搜索文件的操作可能并不陌生。你可能会选择直接使用窗口右上角自带的搜索功能，去搜索指定名称的文件： Window Search\"\rWindow Search\r 如果Windows 10系统，那么你可能会选择更为触手可及的任务栏搜索功能： Taskbar Search\"\rTaskbar Search\r 但它们都有一个通病——搜索速度慢。 ","date":"2021-06-28","objectID":"/posts/listary/:1:0","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"利用索引 接触过数据库的都知道，如果为指定的列建立一个主键索引，那么通过主键进行查询操作时，可以大大地提高查找效率。 那么是否有一种方式，可以为Windows系统中所有的文件建立一个索引，继而通过这种方式，达到快速搜索文件的目的呢？答案是肯定的。 Windows系统下，有许多的软件都提供了索引文件的功能，例如：Listary、uTools、Everything、PowerToys等等。本文介绍的正是Listary搜索工具。 ","date":"2021-06-28","objectID":"/posts/listary/:2:0","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"软件安装 Listary本身是一款收费的软件，但收费只是针对Listary 5。对于正在开发中的Listary 6来说，它的Beta版本是免费的，且功能齐全。 快速下载：Listary 6.0.5.16 ","date":"2021-06-28","objectID":"/posts/listary/:3:0","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"功能介绍 Listary提供多种搜索方式，最基本的使用是通过双击Ctrl键唤醒搜索框，输入关键字对文件、目录或程序进行搜索。 Listary除了基本搜索功能外，还提供了网页检索和快捷命令两种自定义的搜索方式。 通过网页检索，可以完成诸如快速查词、检索指定视频网站中的视频等等功能。 快捷命令则提供自定义命令的功能，结合cmd、powershell可以定义许多丰富的快捷功能，如自定义搜索关键字、指定浏览器打开指定网页或快速复制默认文本等等。 ","date":"2021-06-28","objectID":"/posts/listary/:4:0","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"1.文件搜索 文件搜索不仅局限于文件。Listary提供的搜索功能可以根据程序、文件或目录的全名进行搜索，也可以针对其中文拼音首字母进行搜索。 Search \u0026 Open\"\rSearch \u0026 Open\r 鉴于文件搜索是最基本的功能，不再赘述。 ","date":"2021-06-28","objectID":"/posts/listary/:4:1","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"2.网页检索 通过双击Ctrl键的方式，唤醒Listary搜索框。输入命令opt，你可以快速打开Listary的选项设置。 Search \u0026 Open\"\rSearch \u0026 Open\r 其中，Web Search就是网页搜索。 学过前端的都知道，百度或谷歌在进行搜索的时候，使用的是GET方式，此时搜索的参数会跟在网页Url之后进行传输。 Listary根据网页搜索的特性，使用了一个特殊的占位符{query}，用于替换用户搜索时所输入的参数。 举个例子，假如你在Web Search中配置了如下功能： Web Search\"\rWeb Search\r 此时，Url配置为： http://www.baidu.comd/s?wd={query} 保存配置后，在Listary搜索框中，输入关键字b+空格，即可唤醒该功能。且空格之后所输入的文本，会替换Url中的占位符{query}。 假如，输入文本为Listary，那么经替换后的Url如下： http://www.baidu.comd/s?wd=Listary 演示： Search \u0026 Open\"\rSearch \u0026 Open\r 按下回车键后，Listary便会自动调用默认浏览器，打开指定的网页。 Tip\r\rUrl中的http协议可以改成https协议的链接，一般情况下对于搜索结果无影响。\r\r 在不提供任何的占位符{query}的情况下，配置即等同于直接打开Url。此时，打开Listary搜索框输入关键字并按下回车，即可访问指定网页。 假如，有以下配置： Open Website\"\rOpen Website\r 保存配置，唤醒搜索框输入关键字，回车即可打开Mgtv网站： Directly Open Website\"\rDirectly Open Website\r 网页检索最实用的功能之一是查词，通过定义以下功能，可以完成中英、英中的单词查询： en -\u003e zh\"\ren -\u003e zh\r zh -\u003e en\"\rzh -\u003e en\r Url/en-\u003ezh： https://translate.google.cn/#view=home\u0026op=translate\u0026sl=en\u0026tl=zh-CN\u0026text={query} Url/zh-\u003een： https://translate.google.cn/#view=home\u0026op=translate\u0026sl=zh-CN\u0026tl=en\u0026text={query} 演示： Search \u0026 Open\"\rSearch \u0026 Open\r ","date":"2021-06-28","objectID":"/posts/listary/:4:2","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"3.快捷命令 快捷命令主要是针对系统的一系列命令。如下： Commands\"\rCommands\r 快捷命令也存在所谓的占位符{query}，如果提供了占位符，则需要通过空格来输入指定参数；如果不存在占位符，则可以直接回车键打开。 最基本的快捷命令关键字是cmd和hosts，前者用于打开Windows命令行，后者用于快速修改hosts文件。 同样可以通过自定义的方式，添加快捷命令。 假如有以下快捷命令： Commands\"\rCommands\r 该快捷命令的关键字，可以指定使用Microsoft Edge打开Baidu网页： Specific Open\"\rSpecific Open\r 快捷命令中，各项参数说明如下： 关键字：调用快捷命令的关键字； Title：搜索框中显示的标题； 路径：定义需要打开的程序； 参数：程序所能接受的参数。 快捷命令最强大的地方，在于可以静默调用cmd，可以通过快捷命令，将指定的文本放到剪切板中。如下： echo hey | clip 该条命令可以将文本“hey”放入到剪切板中。 定义以下快捷方式： Commands\"\rCommands\r 保存配置，即可通过该快捷命令，将“hey”文本放入到剪切板中。 Clipboard\"\rClipboard\r Tip\r\r剪切板功能常用于固定格式模板的获取上，通过Listary可以轻松地将各种模板放入剪切板中，从而提高效率。\r\r ","date":"2021-06-28","objectID":"/posts/listary/:4:3","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["System"],"content":"资料参阅 有关Listary的更多内容，请参阅：Listary - docs ","date":"2021-06-28","objectID":"/posts/listary/:5:0","tags":["Efficiency"],"title":"Listary","uri":"/posts/listary/"},{"categories":["Encrypted"],"content":"关于Clash工具 Clash for Windows工具是基于Clash开发的，服务于Windows、macOS平台的网络代理工具。其主要提供添加、使用及订阅代理等服务。 关于Clash for Windows的更多资料，请参阅：Clash for Windows ","date":"2021-06-15","objectID":"/posts/clash/:1:0","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"下载安装 可以从项目的Releases中，选择合适的安装包，下载解压并安装即可。 Releases\"\rReleases\r Quick Download：Clash.for.Windows.Setup.0.15.10.exe ","date":"2021-06-15","objectID":"/posts/clash/:2:0","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"基本配置 关于Clash for Windows的配置，只需要关注三个地方，分别是General、Profiles和Proxies。 ","date":"2021-06-15","objectID":"/posts/clash/:3:0","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"1.General 该选项主要用于软件的一些网络、日志、端口及自启动的设置。如图： General\"\rGeneral\r 其中，重点有四个： Port：本地代理端口； Allow LAN：是否允许来自局域网的连接； System Proxy：是否开启系统代理。开启后，系统的所有连接都会经过当前启用的代理服务器； Start with Windows：是否允许在计算机启动时，同时启动Clash。 ","date":"2021-06-15","objectID":"/posts/clash/:3:1","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"2.Profiles 该选项用于配置代理服务器，允许通过订阅的方式增加代理服务器。如图： Profiles\"\rProfiles\r 此时，只需要输入对应的订阅URL，点击Download，即可获取对应的代理服务器配置文件。 配置文件标签之前的绿色竖条，标志着当前启用的配置文件。 该配置文件可以理解为记录了代理服务器配置的文件，Clash会根据该配置文件，获取其中所有代理服务器，并列举在Proxies中。 ","date":"2021-06-15","objectID":"/posts/clash/:3:2","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"3.Proxies 添加Profiles完毕后，就可以进入Proxies。如图： Proxies\"\rProxies\r 其中代理模式包括四种：Global、Rule、Direct和Script，实际只用到Global和Rule两种模式。 通过实际测试，Global与Rule没有什么差别。 而位于Global和Rule模式下的，就是代理服务器的节点，节点标签之前的绿色竖条，标志着当前启用的代理服务器。 ","date":"2021-06-15","objectID":"/posts/clash/:3:3","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"代理模式 仅介绍两种，全局代理和直连模式。 ","date":"2021-06-15","objectID":"/posts/clash/:4:0","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"全局代理 全局代理\"\r全局代理\r 在Clash的右键菜单中，勾选System Proxy，即可开启全局代理，此时Proxy Mode可以Global，也可以处于Rule。勾选该选项等同于开启General中的System Proxy选项。 全局代理用于一些特殊场景，诸如在Git Bash中无法进行项目代码的拉取等等。 ","date":"2021-06-15","objectID":"/posts/clash/:4:1","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"直连模式 在Clash的右键菜单中，只要是非System Proxy模式，则无论Proxy Mode处于Global还是Rule，则当前都属于直连模式。 直连模式\"\r直连模式\r 直连模式\"\r直连模式\r 一般总是采用直连模式，仅在软件或系统有需要使用代理服务器的地方，通过本地回环地址加端口的方式，去使用代理服务器。 ","date":"2021-06-15","objectID":"/posts/clash/:4:2","tags":["Security"],"title":"Clash for Windows","uri":"/posts/clash/"},{"categories":["Encrypted"],"content":"Post加密原理 Hugo文章的简单加密，使用的是JavaScript中的if判断。此时打开文章页面，会要求输入密码： 如果密码正确，则继续加载页面； 如果密码错误，则返回上一步。 而实现文章页面加密的JavaScript代码也十分简单，如下： \u003cscript\u003e (function() { if('{{ .Params.password }}') { if (prompt('Please enter password.') !== '{{ .Params.password }}') { window.stop(); // 停止页面加载 alert('Sorry! Password wrong.'); // 提示错误信息 history.back(); // 返回上一个页面 } } })(); \u003c/script\u003e 其中，关键的问题有两个： 如何配置.Params.password变量； 如何让文章页面在动态生成时，可以在header标签中嵌入此段代码。 ","date":"2021-06-15","objectID":"/posts/hugo_post_encrypted/:1:0","tags":["Security"],"title":"Hugo Post Encrypted","uri":"/posts/hugo_post_encrypted/"},{"categories":["Encrypted"],"content":"自定义前置参数 Hugo的每一篇文章都拥有所谓的前置参数，该前置参数会在生成其HTML页面的默认模板中，被解析成JavaScript的参数。 假设此时在文章的前置参数中，有如下参数： --- password: 123456 --- 此时，该前置参数的值，可以在生成该post的HTML页面中，通过变量.Params.password进行访问。 ","date":"2021-06-15","objectID":"/posts/hugo_post_encrypted/:2:0","tags":["Security"],"title":"Hugo Post Encrypted","uri":"/posts/hugo_post_encrypted/"},{"categories":["Encrypted"],"content":"页面的动态生成 解决了变量的读取问题后，剩下的便是如何在生成post的默认HTML中，嵌入JavaScript代码了。在使用主题的情况下，Hugo会选用主题中的预设页面，来动态生成文章的页面。 而此时需要关注的是生成posts文章页面的默认模板，该模板位于主题目录下的/layouts/partials/目录中。 技术上来说，你可以在任意位置添加用于加密的JavaScript代码，本篇选择在header标签中添加。 那么，此时应该修改的模板页面应该是header.html，在该页面中的header标签末尾添加JavaScript代码即可： {{- /* Desktop header */ -}} \u003cheader class=\"desktop\" id=\"header-desktop\"\u003e \u003cdiv class=\"header-wrapper\"\u003e \u003cdiv class=\"header-title\"\u003e \u003ca href=\"{{ .Site.Home.RelPermalink }}\" title=\"{{ .Site.Title }}\"\u003e {{- with .Site.Params.header.title -}} {{- with .logo -}} {{- dict \"Src\" . \"Class\" \"logo\" | partial \"plugin/image.html\" -}} {{- end -}} {{- with .pre -}} \u003cspan class=\"header-title-pre\"\u003e{{ . | safeHTML }}\u003c/span\u003e {{- end -}} {{- if .typeit -}} {{- $id := dict \"Content\" .name \"Scratch\" $.Scratch | partial \"function/id.html\" -}} \u003cspan id=\"{{ $id }}\" class=\"typeit\"\u003e\u003c/span\u003e {{- dict $id (slice $id) | dict \"typeitMap\" | merge ($.Scratch.Get \"this\") | $.Scratch.Set \"this\" -}} {{- else -}} {{- .name -}} {{- end -}} {{- with .post -}} \u003cspan class=\"header-title-post\"\u003e{{ . | safeHTML }}\u003c/span\u003e {{- end -}} {{- else -}} {{- .Site.Title -}} {{- end -}} \u003c/a\u003e \u003c/div\u003e \u003cdiv class=\"menu\"\u003e \u003cdiv class=\"menu-inner\"\u003e {{- range .Site.Menus.main -}} {{- $url := .URL | relLangURL -}} {{- with .Page -}} {{- $url = .RelPermalink -}} {{- end -}} \u003ca class=\"menu-item{{ if $.IsMenuCurrent `main` . | or ($.HasMenuCurrent `main` .) | or (eq $.RelPermalink $url) }} active{{ end }}\" href=\"{{ $url }}\"{{ with .Title }} title=\"{{ . }}\"{{ end }}{{ if (urls.Parse $url).Host }} rel=\"noopener noreffer\" target=\"_blank\"{{ end }}\u003e {{- .Pre | safeHTML }} {{ .Name }} {{ .Post | safeHTML -}} \u003c/a\u003e {{- end -}} {{- if .Site.Menus.main -}} \u003cspan class=\"menu-item delimiter\"\u003e\u003c/span\u003e {{- end -}} {{- if .Site.IsMultiLingual -}} \u003ca href=\"javascript:void(0);\" class=\"menu-item language\" title=\"{{ T \"selectLanguage\" }}\"\u003e {{- .Language.LanguageName -}} \u003ci class=\"fas fa-chevron-right fa-fw\"\u003e\u003c/i\u003e \u003cselect class=\"language-select\" id=\"language-select-desktop\" onchange=\"location = this.value;\"\u003e {{- if eq .Kind \"404\" -}} {{- /* https://github.com/dillonzq/LoveIt/issues/378 */ -}} {{- range .Sites -}} {{- $link := printf \"%v/404.html\" .LanguagePrefix -}} \u003coption value=\"{{ $link }}\"{{ if eq . $.Site }} selected{{ end }}\u003e {{- .Language.LanguageName -}} \u003c/option\u003e {{- end -}} {{- else -}} {{- range .AllTranslations -}} \u003coption value=\"{{ .RelPermalink }}\"{{ if eq .Lang $.Lang }} selected{{ end }}\u003e {{- .Language.LanguageName -}} \u003c/option\u003e {{- end -}} {{- end -}} \u003c/select\u003e \u003c/a\u003e {{- end -}} {{- if .Site.Params.search.enable -}} \u003cspan class=\"menu-item search\" id=\"search-desktop\"\u003e \u003cinput type=\"text\" placeholder=\"{{ .Site.Params.search.placeholder | default (T `searchPlaceholder`) }}\" id=\"search-input-desktop\"\u003e \u003ca href=\"javascript:void(0);\" class=\"search-button search-toggle\" id=\"search-toggle-desktop\" title=\"{{ T `search` }}\"\u003e \u003ci class=\"fas fa-search fa-fw\"\u003e\u003c/i\u003e \u003c/a\u003e \u003ca href=\"javascript:void(0);\" class=\"search-button search-clear\" id=\"search-clear-desktop\" title=\"{{ T `clear` }}\"\u003e \u003ci class=\"fas fa-times-circle fa-fw\"\u003e\u003c/i\u003e \u003c/a\u003e \u003cspan class=\"search-button search-loading\" id=\"search-loading-desktop\"\u003e \u003ci class=\"fas fa-spinner fa-fw fa-spin\"\u003e\u003c/i\u003e \u003c/span\u003e \u003c/span\u003e {{- end -}} \u003ca href=\"javascript:void(0);\" class=\"menu-item theme-switch\" title=\"{{ T \"switchTheme\" }}\"\u003e \u003ci class=\"fas fa-adjust fa-fw\"\u003e\u003c/i\u003e \u003c/a\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c!-- Encrypt Code Added Here --\u003e \u003cscript\u003e (function(){ if('{{ .Params.password }}'){ if (prompt('Please enter password.') !== '{{ .Params.password }}'){ window.stop(); alert('Sorry! Password wrong.'); history.back(); } } })(); \u003c/script\u003e \u003c/header\u003e {{- /* Mobile header */ -}} \u003cheader class=\"mobile\" id=\"header-mobile\"\u003e \u003cdiv class=\"header-container\"\u003e \u003cdiv class=\"header-wrapper\"\u003e \u003cdiv class=\"header-title\"\u003e \u003ca href=\"{{ .Site.Home.RelPermalink }}\" title=\"{{ .Site.Title }}\"\u003e {{- with .Site.Params.header.title -}} {{- with .logo -}} {{- dict \"Src\" . \"Class\" \"logo\" | partial \"plugin/image.html\" -}} {{- end -}} {{- with .pre -}} \u003cspan class=\"","date":"2021-06-15","objectID":"/posts/hugo_post_encrypted/:3:0","tags":["Security"],"title":"Hugo Post Encrypted","uri":"/posts/hugo_post_encrypted/"},{"categories":["Encrypted"],"content":"效果测试 假设此时有一篇post具有以下前置参数与内容： --- title: \"Sample Post\" summary: \"none。\" date: 2021-06-15 draft: false password: 123456 --- ## Sample Post Testing passcode. 此时，设置了访问该post的密码为：123456。 部署本地网站后，访问该post。此时JavaScript加密代码生效，会要求用于输入密码进行访问： Password needed\"\rPassword needed\r 密码输入正确后，即可访问文章内容： Enter password\"\rEnter password\r Access successful\"\rAccess successful\r ","date":"2021-06-15","objectID":"/posts/hugo_post_encrypted/:4:0","tags":["Security"],"title":"Hugo Post Encrypted","uri":"/posts/hugo_post_encrypted/"},{"categories":["Encrypted"],"content":"安全性 通过JavaScript的简单加密，本身是不够安全的。 其主要原因有两个： 代码无法保证在何时加载该JS，也许网页具体内容在加载该JS前就被加载完毕了； 对于部署在免费页面的静态网站，实际所有页面的源码是公开的。 针对原因1，通过一定的手段，可以查看到加密网页源码。 Tip\r\r破解步骤： 在不输入任何密码的情况下，点击取消按钮，此时会提示密码错误； 在关闭该密码错误弹窗的瞬间，按下ESC键阻止页面继续加载。 此时，极有几率可以看到加密页面的所有内容。 注意，即使JS中使用了window.stop()，也无法保证代码的加载顺序。 \r\r 针对原因2，显然如果是通过GitHub Page免费页面进行的静态网站部署，其源码实际上存在于公共的GitHub仓库内。 此时，加密的网页其本质上是公开状态的，那么加密已经失去了意义。 Tip\r\rGitHub Page允许部署private仓库中的静态网站，但需要付费。\r\r ","date":"2021-06-15","objectID":"/posts/hugo_post_encrypted/:5:0","tags":["Security"],"title":"Hugo Post Encrypted","uri":"/posts/hugo_post_encrypted/"},{"categories":["System"],"content":"什么是静态网站？ 静态网站，是指内容全部由HTML、CSS、JavaScript等语言组成的网站，其非常适合专注于内容的网站，例如个人博客。静态网站与动态网站相比，具有以下的好处： 占用资源小，速度快。静态网站不需要使用解析器、不需要与数据库进行交互等等特征，使其加载速度天然快于动态网站； 安全。静态网址简洁的特性，也使其可以免疫许多的web攻击方式； 服务端配置简单，仅需要提供web服务器（如：apache、nginx）即可；如果选择挂到GitHub上，则只需要生成静态网站的目录即可； 容易维护。由于静态网站架构的复杂程度要远远小于动态网站架构，也使其维护程度大大降低。 Tip\r\r简而言之，静态网站就是用于展示的HTML网页。在静态网站种种优势的加持下，使其十分适用于个人博客平台的构建。\r\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:1:0","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"静态网站生成工具 静态网站多数情况下，是用于内容的展示上，而究其本质，静态网站是一个部署在web服务器上的目录，该目录中放置了所有网站运行所必须的静态资源，如：HTML页面、CSS文件、JavaScript文件、图片、音频、视频等等。 如果你是一个前端开发者，可以很轻松地使用前端语言与相关网页构筑工具，开发出一个静态网站。但如果你并不是一个前端开发者，或是对前端语言没有十分熟悉，那么你可以借助流行的静态网站生成工具来构筑属于你的静态网站。 Info\r\r市面上有许多流行的静态网站生成工具，常见的有Jekyll、Octopress、Hugo、DocPad、Hexo等等。本文将采用Hugo静态网站生成工具，来搭建一个静态的博客。\r\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:2:0","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"Hugo简介 Hugo是由Go语言实现的静态网站生成工具，同时Hugo提供了海量的主题，结合GitHub/Gitee的免费页面，可以用于个人静态博客的构筑。 Tip\r\r简而言之，Hugo是用于生成静态网站资源目录的工具，其程序的体量十分小，可以运行在多个平台。使用Hugo的目的，仅仅是为了生成静态网站的资源目录，及使用其海量的主题对博客进行美化。\r\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:3:0","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"1.工具下载 Hugo是个开源的项目，其项目的Releases地址为： Releases · gohugoio/hugo (github.com) Info\r\r该项目仅在GitHub上提供，作者没有在Gitee上托管该项目。\r\r 1|a.版本说明 以操作系统Windows-64bit为例，可以看到Hugo的Releases列表中，有两个版本均可用于Windows-64bit操作系统，其分别是： hugo_0.83.1_Windows-64bit.zip hugo_extended_0.83.1_Windows-64bit.zip 其中，hugo_extended版本允许对既定的主题进行修改，而普通的hugo版本是不允许对主题进行修改的。 自行根据个人需求进行下载，本文将采用hugo_extended版本作为演示。 1|b.下载解压 在Releases列表中，选择hugo_extended_0.83.1_Windows-64bit版本，下载并解压，可以得到以下结构的目录： | – hugo_extended_0.83.1_Windows-64bit ​ | – hugo.exe ​ | – LICENSE ​ | – README.md hugo_extended_0.83.1_Windows-64bit\"\rhugo_extended_0.83.1_Windows-64bit\r 进入hugo.exe所在目录，打开命令行工具Windows Terminal/cmd.exe，执行命令： hugo new site MyBlog Windows Terminal\"\rWindows Terminal\r Hugo会在当前目录下，生成一个名为MyBlog的网站目录： hugo_extended_0.83.1_Windows-64bit\"\rhugo_extended_0.83.1_Windows-64bit\r MyBlog目录的初始结构如下： | – MyBlog ​ | – archetypes ​ | – content ​ | – data ​ | – layouts ​ | – static ​ | – themes ​ | – config.toml MyBlog\"\rMyBlog\r Tip\r\r需要注意，MyBlog目录还不是所谓的静态网站资源目录。静态网站资源目录需要在完成所有配置之后，使用hugo.exe命令生成。\r\r 命令hugo.exe主要有两个用途： 本地部署：在本地部署静态网站； 远程部署：生成静态网站资源目录，用于部署在web服务器或免费页面。 而完成这两种部署的前提，是需要进入到MyBlog网站目录中去调用hugo.exe命令。 但受限于Windows添加环境变量的复杂程度，这里选择将hugo.exe拷贝到MyBlog网站目录中，为后续的网站部署作准备。 将命令hugo.exe拷贝到MyBlog目录后，该目录的最终结构如下： | – MyBlog ​ | – archetypes ​ | – content ​ | – data ​ | – layouts ​ | – static ​ | – themes ​ | – config.toml ​ | – hugo.exe MyBlog\"\rMyBlog\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:3:1","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"2.基本配置与主题配置 在网站部署之前，需要进行基本配置和主题配置。 基本配置：可以视为修改config.toml； 主题配置：稍微复杂，需要首先获取到主题目录，而后再对主题目录中的相关文件进行适当的修改。 Warning\r\r配置文件config.toml中的大部分配置，是直接与主题themes挂钩的。如果静态网站更换了主题，那么对应地也需要修改config.toml文件。\r\r 🌟2|a.基本配置：config.toml 网站主题选用LoveIt，针对该主题的一个较为完整的config.toml配置如下，可以复制并修改使用： # ---------------- PartA - Global Setting ---------------- # [en, zh-cn, fr, ...] determines default content language, display language defaultContentLanguage = \"zh-cn\" # Language code, ps: unknow usage languageCode = \"en\" # This title will show on the brower's tab title=\"~ Welcome ~\" # True means allow use emoji in your markdown file enableEmoji = true # when building the site with Hugo, baseURL is the GitHub/Gitee address which can access your static website baseURL = \"https://xxxx.github.io\" # Change the default theme to be use when building the site with Hugo theme = \"LoveIt\" # ---------------- PartB - User-defined Setting ---------------- [params] # LoveIt theme version version = \"0.2.X\" [params.app] # When add as app, this name will be the app's name title = \"MyBlog\" # Your website's icon svgFavicon = \"/moon-stars.svg\" [params.header] # Desktop navigation bar's mode (\"fixed\", \"normal\", \"auto\") desktopMode = \"fixed\" # Mobile navigation bar's mode (\"fixed\", \"normal\", \"auto\") mobileMode = \"auto\" # Navigation bar's setting [params.header.title] # Navigation bar's logo logo = \"\" # Navigation bar's name name = \"Nav Title\" # Information before name, you can use HTML format pre = \"\u003cdiv style='font-family: My Cascadia Code; display: inline-block;'\u003e\" # Information after name, you can use HTML format post = \"\u003c/div\u003e\" # Typing animation typeit = true [params.footer] # Enable footer or not enable = true # User-defined content, HTML format is supported custom = '' # Choose to show hugo copyright and theme info or not hugo = false # Choose to show copyright or not copyright = true # Choose to show author name or not, need variable [author] supported author = true # Year that this website built since = 2019 # ICP info icp = \"\" # License, HTML format is supported license = '\u003ca rel=\"license external nofollow noopener noreffer\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\"\u003eCC BY-NC 4.0\u003c/a\u003e' # Posts card setting [params.section] # Articles that each page showing paginate = 20 # Date format dateFormat = \"01-02\" # Amount of RSS rss = 10 # Tags or Categories card setting [params.list] # Articles that each page showing paginate = 20 # Date format dateFormat = \"01-02\" # Amount of RSS rss = 10 # Theme setting [params.home] # Personal profile [params.home.profile] enable = true # Front page avatar avatarURL = \"/avatar.gif\" # Front page avatar's title title = \"Aloha, I'm dylan. Nice to know u.\" # Front page avatar's subtitle subtitle = \"keep coding, keep breathing.\" # Typing animation support subtitle typeit = true # Choose to show your social account, need variable [params.social] support social = true # Disclaimer info, HTML format supported disclaimer = \"\" # Front page article [params.home.posts] enable = true # Amount of front page articles paginate = 6 # Social information, program will auto concatenated address [params.social] GitHub = \"\" Stackoverflow = \"\" Steam = \"\" Email = \"\" # ---------------- PartC - Menu Setting ---------------- [menu] [[menu.main]] identifier = \"posts\" # you can add extra information before the name (HTML format is supported), such as icons pre = \"\" # you can add extra information after the name (HTML format is supported), such as icons post = \"\" name = \"Posts\" url = \"/posts/\" # title will be shown when you hover on this menu link title = \"\" weight = 1 [[menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"Tags\" url = \"/tags/\" title = \"\" weight = 2 [[menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"Categories\" url = \"/categories/\" title = \"\" weight = 3 # ---------------- Below is other setting ---------------- # Author setting [author] name = \"You\" email = \"\" link = \"\" # Markup related configuration in Hugo [mark","date":"2021-06-07","objectID":"/posts/hugo_blog/:3:2","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"Hugo网站部署 本节将介绍Hugo的两种用途： 在本地部署静态网站； 生成静态网站资源目录，用于部署在web服务器或免费页面。 Tip\r\rHugo本地部署的网站，拥有一个十分突出的优势：在静态网站部署完毕且在运行中时，你可以任意动态地改变配置、文档或图片。网站会随着任意改动的保存，进行即刻的刷新操作，保证网站上展示的内容总是与真实的文档内容一致。\r\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:4:0","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"1.创建博文 Hugo要求在部署网站之前，站内必须拥有至少一篇博文。切换到网站的根目录下，使用以下命令新建一篇markdown博文： hugo new posts/first_post.md\rTip\r\r对于命令hugo new xxxx来说，其本质是在content目录下创建名为xxxx的markdown文件。其中markdown文件模板来自于archetypes/default.md。\r\r 命令运行后，可以看到在content目录下，新增了一个名为posts的目录，且该目录下拥有一个名为first_post.md的文件： /MyBlog/content/posts/first_post.md\"\r/MyBlog/content/posts/first_post.md\r 其中，first_post.md内容如下： --- title: \"First_post\" date: 2021-06-08T04:49:30+08:00 draft: true --- Hugo允许你在文章内容前面添加yaml、toml或者json格式的前置参数。新建的first_post.md中，三个默认前置参数的说明如下： title：文章显示的标题； data：文章显示的创建日期； draft：是否为草稿。在正常的本地部署或生成静态资源目录时，此选项为true的文章，不会被展示在网站上。 关于Hugo中更多markdown前置参数的说明，请参阅：Front Matter 以下是本博客常用的前置参数，示例如下： --- title: \"Title\" summary: \"Front page description.\" date: yyyy-MM-dd draft: false tags: [\"tagsA\", \"tagsB\"] categories: [\"categoriesA\", \"categoriesB\"] lightgallery: true --- 在本地部署网站前，我们修改first_post.md的前置参数，并添加一些段落与文字，方便后期展示。如下： --- title: \"First_post\" date: 2021-06-08T04:49:30+08:00 draft: false summary: \"Front page description.\" tags: [\"tagsA\"] categories: [\"categoriesB\"] --- ## 标题吖 你好吗？ ","date":"2021-06-07","objectID":"/posts/hugo_blog/:4:1","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"2.本地部署 现在，你可以使用hugo命令行，将静态网站部署到本地了。进入MyBlog目录，打开终端并运行以下命令： hugo server\r以上命令，会自动将网站部署在本地的1313端口： 网站部署期间，不可关闭终端\"\r网站部署期间，不可关闭终端\r 通过访问http://localhost:1313，可以看到hugo部署在本地的网站： Homepage\"\rHomepage\r first_post.md\"\rfirst_post.md\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:4:2","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"3.远程部署 本节将介绍如何将Hugo生成的静态网站资源目录，部署到GitHub的免费页面上。关于GitHub Pages简介，可以参考以下链接： GitHub Pages | Websites for you and your projects. Tip\r\r远程部署实际可以区分为：web服务器部署和GitHub/Gitee免费页面的部署。其中，前者无非是将生成的静态网站资源目录放置在服务器上，通过nginx或tomcat等web服务器实现外网的访问，此处不再赘述。\r\r 🌟3|a.创建GitHub仓库 登录GitHub，并创建一个名称格式为username.github.io的远程仓库： new repository\"\rnew repository\r 关于远程仓库的连接，可选使用HTTPS或SSH连接。 HTTPS连接需要提供GitHub的登录密码； SSH连接则需要上传公钥到GitHub上，在连接时提供私钥进行认证： 2phangx-dylan/2phangx-dylan.github.io\"\r2phangx-dylan/2phangx-dylan.github.io\r 🌟3|b.生成静态网站资源目录 进入MyBlog目录，运行以下命令，以生成静态网站资源目录： hugo --baseURL https://2phangx-dylan.github.io Tip\r\r如果你不希望在每次生成静态网站资源目录时，添加baseURL参数，可以选择将该参数配置在config.toml文件中，如：baseURL = \"https://xxxx.github.io\"。\r\r 命令运行后，MyBlog目录下会出现一个名为public的静态网站资源目录： Windows Terminal\"\rWindows Terminal\r public\"\rpublic\r 🌟3|c.托管项目 进入public目录，将当前目录的内容上传到GitHub中，此时需要使用到Git Bash，相关命令如下： git init git add . git commit -m \"update.\" git branch -M main git remote add origin https://github.com/2phangx-dylan/2phangx-dylan.github.io.git git push -u origin main 待项目上传完毕后，GitHub中会出现该资源目录： repository\"\rrepository\r 🌟3|d.访问博客 项目上传完毕后，即可通过https://2phangx-dylan.github.io，访问该博客： 2phangx-dylan.github.io\"\r2phangx-dylan.github.io\r Tip\r\rGitHub Pages的部署需要时间，往往项目上传完毕之后，打开对应的GitHub Pages是无法立即看到网页效果的，此时等待几分钟再重新访问即可。\r\r ","date":"2021-06-07","objectID":"/posts/hugo_blog/:4:3","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["System"],"content":"资料参阅 以上仅是Hugo框架的基本使用与部署步骤，如需获取更多内容，请参阅：Hugo，关于Hugo主题LoveIt的更多内容，请参阅：LoveIt。 ","date":"2021-06-07","objectID":"/posts/hugo_blog/:5:0","tags":["Hugo"],"title":"Hugo Blog","uri":"/posts/hugo_blog/"},{"categories":["Java"],"content":"日志实现 日志实现可以理解为平时所使用的日志系统或日志框架，常见的日志实现，有JUL、log4j、logback、log4j2等等。 日志实现通常由于其架构不一致，导致其使用规则或方式也不太一样，日志等级划分也会有所区别。 简而言之，不同的日志实现拥有不一样的API，因此获取的日志记录对象是不一样的，获取方式也是不一样的。 Tip\r\r多数日志实现所获取的对应日志记录对象都是Logger对象，但需要明确一点，这些Logger对象的实现是不一样的，它们都是各自日志实现中所编写的Logger类，它们并不是同一个类。 如果希望在同一个类中，调用多个不同日志实现提供的Logger对象，请使用Logger的全限定类名。 \r\r ","date":"2020-03-07","objectID":"/posts/log/:1:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志门面 当我们的系统变的更加复杂的时候，我们的日志就容易发生混乱。随着系统开发的进行，可能会更新不同的日志实现，造成当系统中存在不同的日志依赖，让我们难以统一的管理和控制。 就算我们强制要求所有的模块使用相同的日志实现，系统中也难以避免使用其他类似spring、mybatis等其他的第三方框架，它们依赖于我们规定不同的日志实现，而且他们自身的日志系统就有着不一致性，依然会出来日志体系的混乱。 所以我们需要借鉴JDBC的思想，为日志框架提供一个统一的门面框架。借此我们就可以面向这些门面框架的接口规范来开发，避免了直接依赖具体的日志实现。 常见的日志门面： JCL（Jakarta Commons Logging） slf4j（Simple Logging Facade for Java） 常见的日志实现： JUL（Java Util Logging） log4j（Log for Java） logback log4j2（Log for Java 2） slf4j-simple 日志实现或门面的出现顺序： Tip\r\r关于日志实现slf4j-simple，它是随着日志门面slf4j而出现的日志实现，功能较为简单，并不是本文的重点。\r\r ","date":"2020-03-07","objectID":"/posts/log/:2:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志实现JUL JUL全称Java Util Logging，是Java原生的日志实现，使用时不需要另外引入第三方类库，相对于其他日志实现来说其特点是使用方便，能够在小型应用中灵活应用。 JUL日志实现使用的频率并不高，但一旦需要接触此类的代码，仍然要求开发人员能够迅速看懂代码，并理解。 ","date":"2020-03-07","objectID":"/posts/log/:3:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.框架结构 JUL包括了三部分组件，分别是Logger、Appender和Filter，其中Appender也被称为Handler。 JUL Framework\"\rJUL Framework\r Loggers被称为记录器，应用程序通过获取Logger对象，调用其API来发布日志信息，Logger通常是应用程序访问日志系统的入口程序。 Appenders也被称为Handlers，每个Logger都会关联一组Handlers，Logger会将日志交给关联的Handlers处理，由Handlers负责将日志记录。 Handlers实际是一个抽象类，代码中总是由其具体的实现来决定日志记录的最终输出位置是控制台、文件、网络上的其他日志服务异或是操作系统日志。 Filters则是过滤器，根据需要定制哪些信息会被记录，哪些信息会被忽略。 JUL配置文件中，会涉及到另外两个关键设置，即Layouts和Level。Layouts也被称为Formatters，它负责对日志事件中的数据进行转换和格式化，Layouts决定了记录的数据在一条日志记录中的最终显示形式。 Level即日志级别，每条日志消息都有一个关联的日志级别。该级别粗略指导了日志消息的重要性和紧迫，可以将Level与Loggers、Appenders做关联，以对日志消息进行筛选。 一个完整的日志记录过程如下： 用户使用Logger来进行日志记录的行为，Logger可以同时持有若干个Handler，日志输出操作是由Handler完成的； 在Handler输出日志前，会经过Filter的过滤，判断哪些日志级别放行、哪些拦截，Handler会将日志内容输出到指定位置（日志文件、控制台等）； Handler在输出日志时会使用Layout对日志内容进行排版，之后再输出到指定的位置。 ","date":"2020-03-07","objectID":"/posts/log/:3:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.入门案例 入门案例为简单的日志输出过程。所有的日志在无配置文件的情况下，使用ConsoleHandler控制台输出日志。简而言之，日志会在控制台进行显示，而非输出到日志文件或其他位置。 以下是入门案例的示例代码： @Test public void testQuick() { // 1.创建JUL Logger对象无法传入class对象，迂回战术可以获取该类之后获取名字 Logger logger = Logger.getLogger(JulTest.class.getName()); // 2.输出日志的两种方式，其中日志级别共有7种，还有2种特殊级别 logger.info(\"Hello, here is Java Util Logging\"); logger.log(Level.INFO, \"You can also use this way to output log.\"); // 3.尽量不采用拼接字符串的形式，采用占位符的形式，占位符中需要填写索引编号 String name = \"dylan\"; int age = 12; logger.log(Level.INFO, \"[USER]:{0} [AGE]:{1}\", new Object[]{name, age}); } ","date":"2020-03-07","objectID":"/posts/log/:3:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.日志级别 JUL内置了7种基础的日志级别和2种特殊的日志级别。 7种基础的日志级别为： SEVERE（最高等级） WARNING INFO（默认等级） CONFIG FINE FINER FINEST（最低等级） 2种特殊的日志级别，主要用于开关日志： OFF：用于关闭日志记录； ALL：用于启用日志记录。 采用示例的方式，展示7种基础的日志级别： /** * JUL默认的日志级别是Info，所有级别高于等于Info的日志都会被输出控制台。 */ @Test public void testLogLevel() { // 1.获取日志记录器对象，其中getLogger的参数name是此日志对象Logger的名称，可以由logger.getName()取出 final Logger logger = Logger.getLogger(\"cn.dylanphang.jul.JulTest\"); // 2.使用默认的ConsoleHandler输出各级别的日志，默认情况下只有Server、Warning和Info会输出到控制台 logger.severe(\"Level Severe.\"); logger.warning(\"Level Warning.\"); logger.info(\"Level Info.\"); logger.config(\"Level Config.\"); logger.fine(\"Level Fine.\"); logger.finer(\"Level Finer.\"); logger.finest(\"Level Finest\"); } 示例代码运行输出如下： Console Output\"\rConsole Output\r 不难留意到，尽管代码中定义了输出INFO等级以下的日志，但实际控制台中并没有相关的日志信息，这是因为： 默认的日志级别是由RootLogger决定的，所有的Logger对象默认都会继承并使用RootLogger所提供的控制台输出处理器对象ConsoleHandler； 同时，RootLogger的默认日志输出等级为INFO，则所有未经配置的Logger默认也是使用该日志级别。 考虑采用更为直观的方式，打印当前Logger对象的日志等级，及与其关联的处理器对象Handler的数量。示例代码如下： @Test public void testFindDefault() { final Logger logger = Logger.getLogger(\"cn.dylanphang.jul.JulTest\"); System.out.println(\"Default Logger's Level: \" + logger.getLevel()); System.out.println(\"Default Logger's Handlers' Quantity: \" + logger.getHandlers().length); } 运行得到： Console Output\"\rConsole Output\r 这并不意外，默认情况下由于Logger继承并使用RootLogger中的日志等级与处理器对象，因此对于它自身来说，并不拥有任何的日志等级信息与处理器对象。 同样采用更直观的方式打印当前Logger的父日志相关信息。示例代码如下： @Test public void testParentLogger() { final Logger logger = Logger.getLogger(\"cn.dylanphang.jul.JulTest\"); final Logger loggerParent = logger.getParent(); System.out.println(\"Logger's Default Parent Logger is: \" + loggerParent.getClass().getSimpleName()); System.out.println(\"Parent Logger's Level: \" + loggerParent.getLevel()); System.out.println(\"Parent Logger's Handlers' Quantity: \" + loggerParent.getHandlers().length); for (Handler handler : loggerParent.getHandlers()) { System.out.println(\"Default \" + handler.getClass().getSimpleName() + \"'s Level: \" + handler.getLevel()); } } 运行得到： Console Output\"\rConsole Output\r 至此，不难推断出Logger的日志输出等级取决于RootLogger。 除此之外，Logger和Handler的日志等级是相互牵制的，其中等级较高一方的配置生效。 通过更改RootLogger中的日志级别及其ConsoleHandler的日志级别，观察输出结果。示例代码如下： @Test public void testLevel() { // 0.准备工作 final Logger logger = Logger.getLogger(\"cn.dylanphang.jul.JulTest\"); final Logger parent = logger.getParent(); // 1.RootLogger日志等级高于ConsoleHandler日志等级 parent.setLevel(Level.WARNING); parent.getHandlers()[0].setLevel(Level.CONFIG); logger.severe(\"[SEVERE ]Something.\"); logger.warning(\"[WARNING]Something.\"); logger.info(\"[INFO ]Something.\"); logger.config(\"[CONFIG ]Something.\"); System.out.println(\"=============================================\"); // 2.RootLogger日志等级小于ConsoleHandler日志等级 parent.setLevel(Level.FINER); logger.severe(\"[SEVERE ]Something.\"); logger.warning(\"[WARNING]Something.\"); logger.info(\"[INFO ]Something.\"); logger.config(\"[CONFIG ]Something.\"); logger.fine(\"[FINE ]Something.\"); logger.finer(\"[FINER ]Something.\"); } 运行得到： Console Output\"\rConsole Output\r ","date":"2020-03-07","objectID":"/posts/log/:3:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.自定义配置 通常会在单独的配置文件中，集中配置Logger的日志等级、处理器类型等信息。 但作为入门，首先可以了解如何在Java代码中，更改Logger日志级别及配置自定义ConsoleHandler。 如果不希望Logger对象使用RootLogger中的默认日志级别进行输出，则需要对Logger进行单独的配置： 重新设置Logger的日志输出等级； 重新配置Logger的处理器Handler类型，并不再使用RootLogger中提供的默认处理器。 示例代码如下： @Test public void testUserDefined() { // 1.获取日志记录器对象 Logger logger = Logger.getLogger(\"cn.dylanphang.jul.JulTest\"); // 2.配置Logger使其不再继承使用RootLogger中的所有Handler logger.setUseParentHandlers(false); // 3.自定义ConsoleHandler对象，并配置该处理器的日志等级 ConsoleHandler consoleHandler = new ConsoleHandler(); consoleHandler.setLevel(Level.ALL); // 4.为Logger添加自定义的ConsoleHandler logger.addHandler(consoleHandler); // 5.由于Logger默认会使用RootLogger的日志等级，如果希望输出Level.ALL的日志，同时需要设置Logger的日志等级也为Level.ALL // *.否则，Logger将会使用RootLogger的默认日志等级INFO，最终日志只会输出等级高于或等于INFO的内容 logger.setLevel(Level.ALL); // 6.分别输出各等级的日志 logger.severe(\"[SEVERE ]Something.\"); logger.warning(\"[WARNING]Something.\"); logger.info(\"[INFO ]Something.\"); logger.config(\"[CONFIG ]Something.\"); logger.fine(\"[FINE ]Something.\"); logger.finer(\"[FINER ]Something.\"); logger.finest(\"[FINEST ]Something.\"); } 运行得到： Console Output\"\rConsole Output\r 开发中较常使用日志配置方式，是通过logging.properties文件完成的，示例配置如下： # RootLogger的日志级别（默认INFO)，所有的Handler都受限于此日志级别，Handler的日志级别可以比RootLogger的日志级别高 .level=ALL # RootLogger默认的处理器，可以配置多个，所有非手动解除父日志的子日志都将使用这些处理器 handlers=java.util.logging.ConsoleHandler, java.util.logging.FileHandler # ConsoleHandler控制台输出处理器配置 # 指定ConsoleHandler默认日志级别 java.util.logging.ConsoleHandler.level=ALL java.util.logging.ConsoleHandler.encoding=UTF-8 # FileHandler文件输出处理器配置 # 指定FileHandler默认日志级别 java.util.logging.FileHandler.level=WARNING # 日志文件输出路径 java.util.logging.FileHandler.pattern=/dylan%u.log # 单个日志文件大小，单位是bit，1024bit即为1kb java.util.logging.FileHandler.limit=1024*1024*10 # 日志文件数量，如果数量为2，则会生成dylan.log.0文件和dylan.log.1文件，总容量为: (limit * count)bit java.util.logging.FileHandler.count=1 # FileHandler持有的最大并发锁数 java.util.logging.FileHandler.maxLocks=100 # 指定要使用的Formatter类的名称，FileHandler默认使用的是XMLFormatter java.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter # 涉及中文日志就最好加上编码集 java.util.logging.FileHandler.encoding=UTF-8 # 是否以追加方式添加日志内容 java.util.logging.FileHandler.append=true # SimpleFormatter的输出格式配置 java.util.logging.SimpleFormatter.format=%4$s: %5$s [%1$tc]%n # 自定义日志级别，其中“cn.hanna”指的是Logger.getLogger(String name)中的显式入参name！！！ cn.hanna.handlers=java.util.logging.ConsoleHandler cn.hanna.level=INFO # 如果此时不关闭名为cn.hanna的Logger的父日志处理器，则在控制台会同时出现父日志处理器和自定义的处理器，消息将重复输出 cn.hanna.useParentHandlers=false 为测试以上配置文件，可以先构建Maven项目，默认情况下，配置文件需要手动加载，过程如下： 使用getResourceAsStream(String fileName)读取resource目录下的配置文件，获取输入流对象is； 获取LogManager对象，该对象是用于全局配置日志的管理对象，它是单例的，需要使用它来加载应用配置文件； 调用LogManager对象中的readConfiguration(InputStream is)方法加载输入流对象is，RootLogger的日志级别和与之关联的Handler将自动根据logging.properties文件进行配置； 配置文件中特殊命名的Logger，将遵循配置文件中设置：使用ConsoleHandler、日志等级INFO、关闭依赖RootLogger的Handler。 @Test public void testUserDefined() throws IOException { // 1.读取配置文件 final InputStream is = Jul2Test.class.getClassLoader().getResourceAsStream(\"logging.properties\"); // 2.获取LogManager，LogManager是单例对象，并加载应用配置文件logging.properties final LogManager logManager = LogManager.getLogManager(); logManager.readConfiguration(is); // 4.正常输出日志 final Logger loggerNormal = Logger.getLogger(this.getClass().getName()); loggerNormal.severe(\"[SEVERE ]Something.\"); loggerNormal.warning(\"[WARNING]Something.\"); loggerNormal.info(\"[INFO ]Something.\"); loggerNormal.config(\"[CONFIG ]Something.\"); loggerNormal.fine(\"[FINE ]Something.\"); loggerNormal.finer(\"[FINER ]Something.\"); loggerNormal.finest(\"[FINEST ]Something.\"); System.out.println(\"=============================================\"); // 5.指定日志对象的名称，配置文件中对cn.hanna名称的Logger进行了特殊配置 final Logger loggerSpecial = Logger.getLogger(\"cn.hanna\"); loggerSpecial.severe(\"[SEVERE ]Something.\"); loggerSpecial.warning(\"[WARNING]Something.\"); loggerSpecial.info(\"[INFO ]Something.\"); loggerSpecial.config(\"[CONFIG ]Something.\"); loggerSpecial.fine(\"[FINE ]Something.\"); loggerSpecial.finer(\"[FINER ]Somethin","date":"2020-03-07","objectID":"/posts/log/:3:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"5.占位符相关 留意到配置内formatter中的包含了相关占位符，如果希望掌握这一部分的含义，需要首先了解String.format的使用。 考虑以下代码： @Test public void test() { String name = \"Mike\"; double score = 89; Calendar calendar = Calendar.getInstance(); calendar.set(1992, Calendar.JANUARY, 3); final String formatA = String.format(\"[%1$-5s] %2$tF score: (%3$-8.2f)\", name, calendar, score); final String formatB = String.format(\"[%1$-5s] %2$tY-%2$tm-%2$td score: (%3$8.2f)\", name, calendar, score); System.out.println(formatA); System.out.println(formatB); } 运行输出： Console Output\"\rConsole Output\r 可以看到，String.format可以将数据按照指定的格式转换为String类型的数据，其中需要遵循以下规则： %[argument_index$][flags][width][.precision]conversion 参数说明如下： 参数 描述 argument_index$ 格式化参数在String.format中的索引位置，从1开始计算索引 flags 关于此格式化数据的额外格式设定，如左对齐-、是否显示正负数符号+ width 此格式数据所占用的宽度。当宽度大于参数的实际宽度时，会自动将格式化数据右对齐 .precision 需要格式化的是一个浮点数时，可以自定义该浮点数格式化后所需保留的小数点位数 conversion 表示需要格式的数据类型是什么 关于String.format的详细内容，可以参考Formatter，其中提供了大量的关于各种类型的各种格式化占位符信息。 了解String.format后，等同于了解了日志记录的格式化原理了。 日志内部使用的也是String.format对日志输出形式进行格式化，其默认调用格式如下： String.format(format, date, source, logger, level, message, thrown); 参数说明如下： 参数 描述 format SimpleFormatter.format中使用的格式，也是配置文件logging.properties中定义的格式 date 日志的输出日期 source 日志的调用者，如果不存在则会输出日志对象的名称 logger 日志对象的名称 level 日志等级 message 日志信息 thrown 当有异常时，会在日志信息中包含异常信息，如果不存在则不输出 其中，允许进行自定义配置的部分只有format和message，而其余参数都是默认提供的。 调用日志框架的代码中，所提供的即为日志信息message。而通过配置文件，可以更改format的默认格式，即可达到根据个人要求更改日志输出格式的目的。 关于SimpleFormatter的详细内容，可以参考SimpleFormatter，其中包含了更详细的说明与示例。 初步了解相关原理后，再次审视配置文件中日志格式配置： %4$s：索引位4是level，表示日志等级，数据类型是String，使用的conversion为s； %5$s：索引位5是message，表示日志信息，数据类型是String，使用的conversion为s； %1$tc：索引位1是date，表示日志输出日期，数据类型是Date，使用的conversion为tc； %n：换行符。 当运行代码logger.warning(\"[WARNING]Something.\")，将得到指定格式的日志记录，如下： Console Output\"\rConsole Output\r 此时格式与日志输出格式一致。 ","date":"2020-03-07","objectID":"/posts/log/:3:5","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"6.过滤器配置 关于Filter过滤器，了解即可。使用过滤器，需要在代码中使用Logger对象中的setFilter方法，配置一个Filter对象。 Filter是一个函数式接口，源码如下： @FunctionalInterface public interface Filter { /** * Check if a given log record should be published. * @param record a LogRecord * @return true if the log record should be published. */ public boolean isLoggable(LogRecord record); } LogRecord是内部用于获取当前日志消息的对象，JUL将使用我们构建的Filter对象，进行进一步的判定。 LogRecord对象中，封装了对应的日志消息，使用方法getMessage()即可取出。 Filter对象中，如果方法isLoggable()返回false，表示忽略该日志信息；否则，记录日志信息。 测试代码如下： @Test public void test() throws IOException { final InputStream is = Jul3Test.class.getClassLoader().getResourceAsStream(\"logging.properties\"); final LogManager logManager = LogManager.getLogManager(); logManager.readConfiguration(is); final Logger logger = Logger.getLogger(this.getClass().getName()); logger.severe(\"[SEVERE ]Something What.\"); logger.warning(\"[WARNING]Something.\"); logger.info(\"[INFO ]Something.\"); logger.config(\"[CONFIG ]Something.\"); logger.fine(\"[FINE ]Something What.\"); logger.finer(\"[FINER ]Something.\"); logger.finest(\"[FINEST ]Something What.\"); System.out.println(\"=============================================\"); // *.配置过滤器Filter logger.setFilter((x) -\u003e !x.getMessage().contains(\"What\")); logger.severe(\"[SEVERE ]Something What.\"); logger.warning(\"[WARNING]Something.\"); logger.info(\"[INFO ]Something.\"); logger.config(\"[CONFIG ]Something.\"); logger.fine(\"[FINE ]Something What.\"); logger.finer(\"[FINER ]Something.\"); logger.finest(\"[FINEST ]Something What.\"); } 其中使用lambda表达式：!record.getMessage().contains(“What”)。即如果日志记录包含了关键字What，则返回false，表示过滤该条日志信息，不进行记录操作。 运行输出： Console Output\"\rConsole Output\r Filter生效，并成功将包含What的日志记录过滤。 ","date":"2020-03-07","objectID":"/posts/log/:3:6","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"7.完整的配置文件 最后贴一个JUL可用的配置文件示例，其中RootLogger仅使用了ConsoleHandler输出日志： .level=ALL handlers=java.util.logging.ConsoleHandler java.util.logging.ConsoleHandler.level=ALL java.util.logging.ConsoleHandler.encoding=UTF-8 java.util.logging.FileHandler.level=INFO java.util.logging.FileHandler.pattern=/sample%u.log java.util.logging.FileHandler.limit=1024*1024*10 java.util.logging.FileHandler.count=1 java.util.logging.FileHandler.maxLocks=100 java.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatter java.util.logging.FileHandler.encoding=UTF-8 java.util.logging.FileHandler.append=true java.util.logging.SimpleFormatter.format=%4$s: %5$s [%1$tc]%n cn.xyz.handlers=java.util.logging.ConsoleHandler, java.util.logging.FileHandler cn.xyz.level=INFO cn.xyz.useParentHandlers=false 关于其他的Handler不作演示了，因为实际遇到的情况很少，有需要的时候查阅相关官方资料即可。 推荐将Handler的日志级别设置为ALL，然后通过各自的Logger对象，进行日志级别的控制。这样在配置文件中，只需要配置特定的Handler一次，即可让多个Logger对象进行使用。 默认情况下，如果不将useParentHandlers设置为false，那么Logger会同时使用RootLogger中的Handler。 ","date":"2020-03-07","objectID":"/posts/log/:3:7","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志实现Log4j Log4j全称是Log for Java，它是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输出的位置是控制台、文件还是GUI组件，输出位置甚至可以是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等。 使用Log4j也可以控制每一条日志的输出格式，通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。 ","date":"2020-03-07","objectID":"/posts/log/:4:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.入门案例 依旧使用Maven构建项目，此时需要引入Log4j的依赖： \u003cdependency\u003e \u003cgroupId\u003elog4j\u003c/groupId\u003e \u003cartifactId\u003elog4j\u003c/artifactId\u003e \u003cversion\u003e1.2.17\u003c/version\u003e \u003c/dependency\u003e Log4j日志实现在默认情况下，要求提供配置文件。如果resource目录下不存在对应的log4j.properties配置文件，则控制台中会输出相应的警告信息。譬如以下代码： @Test public void test() { // 1.在没有log4j.properties的情况下，获取日志记录器对象Logger Logger logger = Logger.getLogger(Log4jTest.class); // 2.尝试输出日志记录 logger.info(\"Hey, log4j.\"); } 此时控制台不会输出对应的日志信息，取而代之仅会输出警告信息： Console Output\"\rConsole Output\r 接触过JUL的都知道，普通JUL的Logger如果没有进行额外的配置，默认是继承并使用RootLogger的配置，而不会出现任何警告信息。 同样地，Log4j中也存在RootLogger。但由于默认情况下Log4j中的RootLogger不具有任何的Appender（即Handler），因此直接使用Log4j，会出现警告信息。 如果代码仅为了测试某项功能，并不想编写复杂的log4j.properties，可以考虑使用Log4j中提供的默认配置。 需要加载Log4j中的默认Appender，只需要在获取Logger前使用BasicConfigurator.configure()加载默认配置即可。 以下为BasicConfigurator中configure()方法的源码： /** Add a {@link ConsoleAppender} that uses {@link PatternLayout} using the {@link PatternLayout#TTCC_CONVERSION_PATTERN} and prints to \u003ccode\u003eSystem.out\u003c/code\u003e to the root category. */ static public void configure() { Logger root = Logger.getRootLogger(); root.addAppender(new ConsoleAppender( new PatternLayout(PatternLayout.TTCC_CONVERSION_PATTERN))); } 古早时期的源码格式有点不太现代，但意义仍旧明确，如下： 为RootLogger对象添加一个Appender，其中Appender的类型为控制器输出的ConsoleAppender，输出的格式遵循PatternLayout.TTCC_CONVERSION_PATTERN变量。 以下为PatternLayout.TTCC_CONVERSION_PATTERN源码： /** A conversion pattern equivalent to the TTCCCLayout. Current value is \u003cb\u003e%r [%t] %p %c %x - %m%n\u003c/b\u003e. */ public final static String TTCC_CONVERSION_PATTERN = \"%r [%t] %p %c %x - %m%n\"; 关于PatternLayout的相关格式化规则，后续会列举出来。 于是，使用以下代码在加载默认配置的前提下，尝试输出日志： @Test public void testQuick() { // 1.初始化配置信息，使用默认的配置，如果不加载默认配置同时不具有log4j.properties配置文件，程序将发出警告 BasicConfigurator.configure(); // 2.获取日志记录器对象Logger Logger logger = Logger.getLogger(Log4jTest.class); // 3.日志记录输出 logger.info(\"Hey, log4j.\"); } 此时控制台输出为： Console Output\"\rConsole Output\r 日志输出成功。 ","date":"2020-03-07","objectID":"/posts/log/:4:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.日志级别 Log4j中的日志级别与JUL的不同，Log4j一共提供了6种日志级别： FATAL：严重错误，一般会造成系统崩溃并终止运行； ERROR：错误信息，不会影响系统运行； WARN：警告信息，可能会发生问题； INFO：运行信息，数据连接、网络连接、I/O操作等等； DEBUG：调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别； TRACE：追踪信息，记录程序所有的流程信息。 参考以下示例代码： @Test public void testQuick() { // 1.初始化配置信息，使用默认的配置，如果不加载默认配置同时不具有log4j.properties配置文件，程序将发出警告 BasicConfigurator.configure(); // 2.获取日志记录器对象Logger Logger logger = Logger.getLogger(Log4jTest.class); // 3.日志级别测试 logger.fatal(\"[FATAL] 严重错误，一般会造成系统崩溃并终止运行。\"); logger.error(\"[ERROR] 错误信息，不会影响系统运行。\"); logger.warn(\"[WARN] 警告信息，可能会发生问题。\"); logger.info(\"[INFO] 运行信息，数据连接、网络连接、I/O操作等等。\"); logger.debug(\"[DEBUG] 调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别。\"); logger.trace(\"[TRACE] 追踪信息，记录程序所有的流程信息。\"); } 运行输出，得到： Console Output\"\rConsole Output\r 输出的日志仍然由默认的日志级别所决定，其中默认级别为DEBUG。 为了测试默认日志级别，可以使用以下代码测试RootLogger： 使用getRootLogger()获取RootLogger对象； 使用RootLogger中的相关方法，获取日志对象的日志等级及其关联的Appender详情。 @Test public void testDetails() { // 1.初始化配置信息，使用默认的配置，如果不加载默认配置，将无法正常运行 BasicConfigurator.configure(); // 2.获取日志记录器对象RootLogger final Logger rootLogger = Logger.getRootLogger(); // 3.输出配置详情 System.out.println(\"Logger level: \" + rootLogger.getLevel()); final Enumeration allAppenders = rootLogger.getAllAppenders(); while (allAppenders != null \u0026\u0026 allAppenders.hasMoreElements()) { final Appender appender = (Appender) allAppenders.nextElement(); System.out.println(\"Appender is: \" + appender.getClass().getSimpleName()); } } 运行输出： Console Output\"\rConsole Output\r 注意，与JUL中的Handler不一样，对于Log4j中的Appender来说，它们不具有日志等级。 Log4j中只有Logger对象具有日志等级。 ","date":"2020-03-07","objectID":"/posts/log/:4:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.相关组件 Log4j主要由Loggers(日志记录器)、Appenders（输出端）和Layout（日志格式化器）组成，说明如下： Loggers：控制日志的输出级别与日志是否输出； Appenders：指定日志的输出方式（输出到控制台、文件等）； Layout：控制日志信息的输出格式。 🌟3|a.Logger 日志记录器，负责收集处理日志记录，Logger的实例命名通常是类的全限定类名。Logger的名字大小写敏感，其命名有继承机制。 例如：name为org.apache.commons的logger会继承name为org.apache的logger。 自log4j 1.2版以来， Logger类已经取代了Category类。对于熟悉早期版本的log4j的人来说，Logger类可以被视为Category类的别名。 🌟3|b.Appenders Appender用来指定日志输出到哪个地方，可以同时指定日志的输出目的地。 Log4j常用的输出目的地有以下几种： 输出端类型 作用 ConsoleAppender 将日志输出到控制台 FileAppender 将日志输出到文件中 DailyRollingFileAppender 将日志输出到一个日志文件，周期为天，即每天输出 RollingFileAppender 将日志信息输出到一个日志文件，并且指定文件的大小，当超过指定大小，会自动将文件重命名，同时产生一个新的文件 JDBCAppender 将日志信息保存到数据库中 🌟3|c.Layouts 布局器Layouts用于控制日志输出内容的格式，我们可以使用各种自定义格式输出日志。 Log4j常用的Layouts有以下几种: 格式化器类型 作用 HTMLLayout 格式化日志输出为HTML表格形式 SimpleLayout 简单的日志输出格式，打印的日志格式为info-message PatternLayout 最强大的格式化方式，可以根据自定义格式输出日志，如果没有指定转换格式，则使用默认的转换格式 PatternLayout中的格式化规则： * log4j采用类似C语言的printf函数的打印格式格式化日志信息，具体的占位符及其含义如下： %m 输出代码中指定的日志信息 %p 输出优先级，及DEBUG、INFO等 %n 换行符（Windows平台的换行符为\"\\n\"，Unix平台为\"\\n\"） %r 输出自应用启动到输出该 log 信息耗费的毫秒数 %c 输出打印语句所属的类的全名 %t 输出产生该日志的线程全名 %d 输出服务器当前时间，默认为ISO8601，也可以指定格式，如：%d{yyyy年MM月dd日 HH:mm:ss} %l 输出日志时间发生的位置，包括类名、线程、及在代码中的行数。如：Test.main(Test.java:10) %F 输出日志消息产生时所在的文件名称 %L 输出代码中的行号 %% 输出一个\"%\"字符 * 可以在%与字符之间加上修饰符来控制最小宽度、最大宽度和文本的对其方式。如： %5c 输出category名称，最小宽度是5，category\u003c5，默认的情况下右对齐 %-5c 输出category名称，最小宽度是5，category\u003c5，\"-\"号指定左对齐,会有空格 %.5c 输出category名称，最大宽度是5，category\u003e5，就会将左边多出的字符截掉，\u003c5不会有空格 %20.30c category名称\u003c20补空格，并且右对齐，\u003e30字符，就从左边交远销出的字符截掉 ","date":"2020-03-07","objectID":"/posts/log/:4:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.自定义配置 使用Log4j一般不需要显式地加载配置文件，对于Maven项目来说，程序会自动扫描resources目录下的log4j.properties配置文件。 一个完整的log4j.properties配置文件如下： # 指定日志的输出级别与输出端 log4j.rootLogger=INFO, Console, UserDefinedName, logDB # 控制台输出配置 log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=%d [%t] %-5p [%c] - %m%n # 文件输出配置 log4j.appender.UserDefinedName=org.apache.log4j.DailyRollingFileAppender # 指定日志的输出路径 log4j.appender.UserDefinedName.File=log4j.log # 是否以追加日志的形式添加 log4j.appender.UserDefinedName.Append=true # 使用自定义日志格式化器 log4j.appender.UserDefinedName.layout=org.apache.log4j.PatternLayout # 指定日志的输出格式 log4j.appender.UserDefinedName.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss} [%t:%r] - [%p] %m%n # 指定日志的文件编码 log4j.appender.UserDefinedName.encoding=UTF-8 # MySQL输出配置 log4j.appender.logDB=org.apache.log4j.jdbc.JDBCAppender log4j.appender.logDB.layout=org.apache.log4j.PatternLayout log4j.appender.logDB.Driver=com.mysql.cj.jdbc.Driver log4j.appender.logDB.URL=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8\u0026useAffectedRows=true log4j.appender.logDB.User=root log4j.appender.logDB.Password=root log4j.appender.logDB.Sql=INSERT INTO log(project_name, create_date, level, category, file_name, thread_name, line, all_category, message) \\ values('log4j', '%d{yyyy-MM-dd HH:mm:ss}', '%p', '%c', '%F', '%t', '%L', '%l', '%m') 此时，配置文件中规定了日志输出等级为INFO，同时RootLogger设置了三个不同的Appender，分别是： ConsoleAppender：配置中被命名为Console； DailyRollingFileAppender：配置中被命名为UserDefinedName； JDBCAppender：配置中被命名为logDB。 RootLogger的默认日志输出级别配置在首行首位，随后紧跟的是相关联的Appender的名称，表示其默认支持输出的方式有哪些。 配置文件中可以配置多个类型可重复的Appender，但Appender之间的命名则不可重复。 配置中包含了sql输出日志的方式，对应的log表的创建代码为： CREATETABLE`log`(`log_id`INT(11)NOTNULLAUTO_INCREMENT,`project_name`VARCHAR(255)DEFAULTNULLCOMMENT'项目名称',`create_date`VARCHAR(255)DEFAULTNULLCOMMENT'创建时间',`level`VARCHAR(255)DEFAULTNULLCOMMENT'优先级',`category`VARCHAR(255)DEFAULTNULLCOMMENT'所在类的全名',`file_name`VARCHAR(255)DEFAULTNULLCOMMENT'输出日志消息产生时所在的文件名称 ',`thread_name`VARCHAR(255)DEFAULTNULLCOMMENT'日志事件的线程名',`line`VARCHAR(255)DEFAULTNULLCOMMENT'行号',`all_category`VARCHAR(255)DEFAULTNULLCOMMENT'日志事件的发生位置',`message`VARCHAR(4000)DEFAULTNULLCOMMENT'输出代码中指定的消息',PRIMARYKEY(`log_id`));如果希望让特定名称的Logger使用特定的配置，则需要在配置文件中定义以下格式的键名：log4j.logger.logger_name。 其中，logger_name就是指定Logger的名称，Log4j会自动为命名为logger_name的Logger应用配置。 但由于Logger仍然是隶属于RootLogger，因此日志输出默认情况下仍旧是累加的形式。 Example\r\r例如，RootLogger使用了ConsoleAppender，同时特定名称的Logger也使用了ConsoleAppender，那么此时控制台将输出两次日志记录，一次为Logger继承自RootLogger的输出，另一次则为Logger自身的输出。\r\r 那么日志输出等级是否也是累加的形式呢？答案是否定的。日志等级取决于Logger和RootLogger，并以日志等级较高的一方为基准。 Example\r\r例如，RootLogger和Logger同时使用了ConsoleAppender，但输出等级则分别为INFO和WARN，此时控制台输出的日志等级仅有高于等于WARN的记录，即使此时RootLogger的等级为INFO。\r\r 结合配置文件说明，假如有如下的配置文件： # 指定日志的输出级别与输出端 log4j.rootLogger=INFO, Console # 控制台输出配置 log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=%d [%t] %-5p [%c] - %m%n # 让名为“cn.hanna”的logger使用名为Another的Appender # 此时仍会使用rootLogger中的控制台输出，而Level则以两者间较高的为准 log4j.logger.cn.hanna=WARN, Console 配置表明，RootLogger和名为cn.hanna的Logger使用同一个ConsoleAppender，但日志等级不一致。 测试代码如下： @Test public void testAnother() { // 1.获取日志记录器对象Logger Logger logger = Logger.getLogger(\"cn.hanna\"); // 2.日志级别测试 logger.fatal(\"[FATAL] 严重错误，一般会造成系统崩溃并终止运行。\"); logger.error(\"[ERROR] 错误信息，不会影响系统运行。\"); logger.warn(\"[WARN] 警告信息，可能会发生问题。\"); logger.info(\"[INFO] 运行信息，数据连接、网络连接、I/O操作等等。\"); logger.debug(\"[DEBUG] 调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别。\"); logger.trace(\"[TRACE] 追踪信息，记录程序所有的流程信息。\"); } 运行输出： Console Output\"\rConsole Output\r 控制台对日志进行了两次输出，且输出的日志等级都是WARN以上的。 如何让普通的Logger不继承使用RootLogger中的Appender呢？或者说，如何让Logger仅进行一次日志输出呢？ 如果一定需要使用ConsoleAppender，但不希望控制台输出两次记录，有两种方式： 摒弃RootLogger的输出，即断开指定Logger与RootLogger的继承关系； 摒弃Logger的输出，即指定名称的Logger直接使用RootLogger关联的Appender，不再额外指定。 如果选择断开指定Logger与RootLogger的继承关系，需修改配置文件如下： # 指定日志的输出级别与输出端 log4j.rootLogger=INFO, Console # 控制台输出配置 log4j.appe","date":"2020-03-07","objectID":"/posts/log/:4:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"5.完整的配置文件示例 同样，在此给出一个完整的log4j.properties配置文件示例： log4j.rootLogger=INFO, Console log4j.appender.Console=org.apache.log4j.ConsoleAppender log4j.appender.Console.layout=org.apache.log4j.PatternLayout log4j.appender.Console.layout.ConversionPattern=%d [%t] %-5p [%c] - %m%n log4j.appender.UserDefinedName=org.apache.log4j.DailyRollingFileAppender log4j.appender.UserDefinedName.File=log4j.log log4j.appender.UserDefinedName.Append=true log4j.appender.UserDefinedName.layout=org.apache.log4j.PatternLayout log4j.appender.UserDefinedName.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss} [%t:%r] - [%p] %m%n log4j.appender.UserDefinedName.encoding=UTF-8 log4j.appender.logDB=org.apache.log4j.jdbc.JDBCAppender log4j.appender.logDB.layout=org.apache.log4j.PatternLayout log4j.appender.logDB.Driver=com.mysql.cj.jdbc.Driver log4j.appender.logDB.URL=jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8\u0026useAffectedRows=true log4j.appender.logDB.User=root log4j.appender.logDB.Password=root log4j.appender.logDB.Sql=INSERT INTO log(project_name, create_date, level, category, file_name, thread_name, line, all_category, message) \\ values('log4j', '%d{yyyy-MM-dd HH:mm:ss}', '%p', '%c', '%F', '%t', '%L', '%l', '%m') log4j.appender.Another=org.apache.log4j.DailyRollingFileAppender log4j.appender.Another.File=hanna.log log4j.appender.Another.Append=true log4j.appender.Another.layout=org.apache.log4j.PatternLayout log4j.appender.Another.layout.ConversionPattern=%-d{yyyy-MM-dd HH:mm:ss} [%t:%r] - [%p] %m%n log4j.appender.Another.encoding=UTF-8 log4j.logger.cn.xyz=WARN, Another log4j.additivity.cn.xyz=false 其中，log4j.appeder.appender_name中的appender_name为相应Appender的名称，该名称可以自行定义。 ","date":"2020-03-07","objectID":"/posts/log/:4:5","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志门面JCL JCL全称Jakarta Commons Logging，是Apache提供的一个通用日志API，它为“所有的Java日志实现”提供了一个统一的接口。 JCL自身提供了一个简单的日志实现SimpleLog，但功能非常弱，一般不会单独使用它。 JCL Framework\"\rJCL Framework\r 在代码中使用JCL的代码获取Log对象，此时底层日志实现既可以使用JUL，也可以使用Log4j或SimpleLog。 ","date":"2020-03-07","objectID":"/posts/log/:5:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.日志级别 JCL日志门面中所支持的日志级别，与Log4j中提供的默认日志级别一致。 即无论你使用的是哪种日志实现，其所提供的日志等级只有六种，回顾一下，分别为： FATAL：严重错误，一般会造成系统崩溃并终止运行； ERROR：错误信息，不会影响系统运行； WARN：警告信息，可能会发生问题； INFO：运行信息，数据连接、网络连接、I/O操作等等； DEBUG：调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别； TRACE：追踪信息，记录程序所有的流程信息。 ","date":"2020-03-07","objectID":"/posts/log/:5:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.入门案例 以Maven项目为示例，最基本的情况下，需要导入JCL依赖： \u003cdependency\u003e \u003cgroupId\u003ecommons-logging\u003c/groupId\u003e \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e \u003cversion\u003e1.2\u003c/version\u003e \u003c/dependency\u003e JCL使用同一套代码来获取日志记录器Log对象，注意，日志记录器不再是Logger对象了。 获取Log对象的方法也很简单，只需要使用JCL中提供了LogFactory类中的静态方法getLog()即可。 那么，JCL如何确定底层所使用的日志门面是什么呢？ JCL底层有一个用于存储其所支持的日志实现的全限定类名的数组，一旦按顺序成功创建了某个日志的实现，将不再继续往后创建其他的日志，默认使用当下创建成功的日志实现。 JCL日志门面支持的日志实现数组： private static final String[] classesToDiscover = new String[]{\"org.apache.commons.logging.impl.Log4JLogger\", \"org.apache.commons.logging.impl.Jdk14Logger\", \"org.apache.commons.logging.impl.Jdk13LumberjackLogger\", \"org.apache.commons.logging.impl.SimpleLog\"}; JCL获取具体日志实现的代码： for(int i = 0; i \u003c classesToDiscover.length \u0026\u0026 result == null; ++i) { result = this.createLogFromClass(classesToDiscover[i], logCategory, true); } 不难看出，JCL将会按照String[] classesToDiscover的顺序去创建Logger对象，一旦创建成功，则会跳出for循环。 其中日志门面优先级为：Log4JLogger \u003e Jdk14Logger \u003e Jdk13LumberjackLogger \u003e SimpleLog。 注意，此时日志门面的使用规则，并不是根据是否存在配置文件决定，而是根据当前环境是否有指定日志实现的依赖而决定。 Example\r\r例如，环境中拥有Log4j的依赖，即便没有Log4j配置文件的存在，JCL仍然默认使用Log4j作为日志实现。显然，此时会出现警告，JCL也并不会因为不存在Log4j配置文件，而选择使用JUL日志实现。 如果希望使用的是JUL日志实现，只需要将Log4j的依赖从pom.xml中剔除并更新即可。 \r\r 以下为简单的JCL测试代码： package cn.dylanphang.jcl; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import org.junit.Test; /** * @author dylan */ public class JclTest { @Test public void testQuick() { // 1.创建日志记录器对象Log Log log = LogFactory.getLog(JclTest.class); // 2.日志级别测试 log.fatal(\"[FATAL] 严重错误，一般会造成系统崩溃并终止运行。\"); log.error(\"[ERROR] 错误信息，不会影响系统运行。\"); log.warn(\"[WARN] 警告信息，可能会发生问题。\"); log.info(\"[INFO] 运行信息，数据连接、网络连接、I/O操作等等。\"); log.debug(\"[DEBUG] 调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别。\"); log.trace(\"[TRACE] 追踪信息，记录程序所有的流程信息。\"); } } JCL在选用不同的日志实现时，其差别主要在于不同的日志实现间具有不同的输出效率，及其所支持的输出位置的不同等等。 至于日志格式，无论是Log4j还是JUL，它们都是支持根据配置文件来更改日志格式的，几乎没有差别。 ","date":"2020-03-07","objectID":"/posts/log/:5:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志门面Slf4j slf4j的全称是Simple Logging Facade for Java，简单日志门面主要是为了给Java日志访问提供一套标准、规范的API接口，其主要的意义在于提供接口，具体的实现可以交由其他日志实现，例如log4j或logback等。 slf4j也有提供功能较为简单的日志实现，但一般不用。对于Java项目而言，日志会选择sl4j-api作为日志门面，再配上具体的日志实现log4j、logback等一起使用，日志门面和日志实现直接需要使用桥接器建立联系。 为什么在具有JCL日志门面的前提下，仍然要使用slf4j作为日志门面？ slf4j日志门面具有以下优势： 使用slf4j框架，可以在部署时迁移到所需的日志记录框架； slf4j提供了对所有流行的日志实现的绑定，例如log4j、JUL、logback、log4j2等； 无论使用哪种绑定，slf4j都支持参数化日志记录消息。由于slf4j将应用程序和日志记录框架分离，因此可以轻松编写独立于日志记录框架的应用程序。而无需担心用于编写应用程序的日志记录框架； slf4j提供了一个简单的Java工具，称为迁移器。使用此工具，可以迁移现有使用日志实现JCL、Log4j或JUL的项目到slf4j。 ","date":"2020-03-07","objectID":"/posts/log/:6:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.日志级别 slf4j日志门面，提供了5个不同的基本日志级别，分别是： ERROR：错误信息，不会影响系统运行； WARN：警告信息，可能会发生问题； INFO：运行信息，数据连接、网络连接、I/O操作等等； DEBUG：调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别； TRACE：追踪信息，记录程序所有的流程信息。 ","date":"2020-03-07","objectID":"/posts/log/:6:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.入门案例 案例使用Maven创建，并使用slf4j中的简单日志实现进行示例，需要引入slf4j的依赖，和其简单日志实现slf4j-simple的依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-simple\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e slf4j作为日志门面时，获取日志记录对象为Logger，获取方式是通过slf4j中的LoggerFactory类提供的静态方法getLogger()。 示例代码： import org.junit.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * @author dylan */ public class Slf4jTest { @Test public void testQuick() { // 1.创建日志记录器对象Logger Logger logger = LoggerFactory.getLogger(Slf4jTest.class); // 2.输出各等级日志，slf4j默认的日志等级是DEBUG logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); // 3.使用占位符输出日志信息 logger.info(\"用户信息：{}, {}\", \"dylan\", 12); // 4.将异常信息写入日志 try { @SuppressWarnings(\"all\") int i = 1 / 0; } catch (Exception e) { logger.info(\"出现异常：\", e); } } } 输出结果省略。 ","date":"2020-03-07","objectID":"/posts/log/:6:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.绑定日志实现 绑定日志实现主要是针对新项目而言的，当你需要选择新项目系统构成时，为了便于日后日志实现可能作出的改变，应当选用支持更多日志实现的slf4j作为日志门面，使用它提供的API来获取日志记录对象。 即使你可能在日后需要从JUL转为log4j，如果一开始选择使用slf4j日志门面，那么未来需要从JUL转为log4j日志实现时，也无须改动代码，只需要更改依赖、添加log4j.properties配置文件即可。 通过日志绑定，slf4j可以支持各种日志实现。绑定日志实现的步骤如下： 添加slf4j-api的依赖； 使用slf4j的API在项目中进行统一的日志记录； 绑定具体的日志实现框架： 绑定已经实现了slf4j的日志实现，可直接添加对应依赖，如logback、slf4j-simple； 绑定没有实现slf4j的日志实现，先添加日志适配器，再添加日志实现的依赖，如log4j、JUL。 注意，slf4j有且仅有一个日志实现框架的绑定（如果出现多个，则默认使用第一个日志实现依赖）。 Concrete Bindings\"\rConcrete Bindings\r 事实上，所谓的绑定等同于引入依赖。对应依赖引入关系如下： \u003c!-- slf4j-api日志门面，需要使用此API获取日志记录对象 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003c!-- logback，自动引入了logback-core --\u003e \u003cdependency\u003e \u003cgroupId\u003ech.qos.logback\u003c/groupId\u003e \u003cartifactId\u003elogback-classic\u003c/artifactId\u003e \u003cversion\u003e1.2.3\u003c/version\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003c!-- slf4j-simple --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-simple\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003c!-- log4j --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-log4j12\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003elog4j\u003c/groupId\u003e \u003cartifactId\u003elog4j\u003c/artifactId\u003e \u003cversion\u003e1.2.17\u003c/version\u003e \u003c/dependency\u003e \u003c!-- JUL --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-jdk14\u003c/artifactId\u003e \u003cversion\u003e1.7.25\u003c/version\u003e \u003c/dependency\u003e \u003c!-- JCL， 如果不提供log4j的依赖，则默认使用JUL日志实现，那实际上直接使用slf4j-jdk14即可； 如果提供了log4j的依赖，那实际上可以被替换slf4j-log4j12. --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-jcl\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e ","date":"2020-03-07","objectID":"/posts/log/:6:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.桥接旧的日志实现 桥接Bridging则主要针对旧项目而言，当旧项目没有选择使用slf4j作为日志门面时，那意味着项目使用的要么是JCL日志门面，要么则是直接使用了log4j或JUL日志实现。 项目一旦需要使用更为高效的日志实现logback或log4j2时，在不改动旧代码的情况下，可以使用slf4j提供的Bridging桥接功能，将JCL或log4j、JUL日志门面或实现桥接到slf4j-api中。 一旦桥接到slf4j-api后，就可以使用绑定功能，将日志无缝转换为新的日志实现。此时需要提供新日志实现的配置文件，同时需要保留旧的日志实现配置文件。 所以，为了防止从旧的日志门面或实现桥接为slf4j-api后，又通过绑定功能输出为原本旧的日志门面或实现的情况发生，以下依赖不能同时引入，否则将会造成Out of Memory错误： jcl-over-slf4j | slf4j-jcl； log4j-over-slf4j | slf4j-log4j12； jul-to-slf4j | slf4j-jdk14； log4j-to-slf4j | log4j-slf4j-impl。 Tip\r\r桥接功能仅针对JCL、log4j、JUL、log4j2等日志门面或日志实现。因为后续的日志实现logback、slf4j-simple都默认使用slf4j作为日志门面，不存在需要桥接的情况。\r\r 桥接解决的是项目中日志遗留问题，当系统中存在之前的API，可以通过桥接转换到slf4j的实现： 先取出之前老的日志实现依赖，即移除老的日志实现依赖； 添加slf4j提供的桥接组件，桥接组件不可以桥接到老的日志实现； 为项目添加slf4j的具体实现。 Legacy\"\rLegacy\r 注意，如果项目使用的是log4j2的日志实现，此时需要使用的桥接器是log4j-to-slf4j.jar，该桥接器是用于log4j2桥接slf4j日志门面的。log4j-over-slf4j.jar则是用于log4j桥接slf4j日志门面。 ","date":"2020-03-07","objectID":"/posts/log/:6:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志实现Logback logback是由log4j创始人设计的另一个开源日志组件，性能要比log4j好。 logback主要分为三个模块： logback-core：其它两个模块的基础模块； logback-classic：它是log4j的一个改良版本，同时它完整实现了slf4j的API； logback-access：访问模块与Servlet容器继承提供通过Http来访问日志的功能。 ","date":"2020-03-07","objectID":"/posts/log/:7:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.日志级别 logback默认使用slf4j的API，因此日志级别与slf4j日志门面提供的日志级别一致。 另外，有2种特殊的日志级别，用于开关日志： OFF：用于关闭日志记录； ALL：用于启用日志记录。 ","date":"2020-03-07","objectID":"/posts/log/:7:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.入门案例 同样采用Maven项目，导入依赖： \u003cdependency\u003e \u003cgroupId\u003ech.qos.logback\u003c/groupId\u003e \u003cartifactId\u003elogback-classic\u003c/artifactId\u003e \u003cversion\u003e1.2.3\u003c/version\u003e \u003c/dependency\u003e 使用logback需要导入logback-core和logback-classic，由于Maven会自动导入依赖，只需要引入logback-classic，即可以自动关联logback-core依赖了。 logback在设计之初就已经是支持slf4j日志门面了，可以选择性排除由logback-classic引入的slf4j-api，使用一个更新的slf4j版本。 \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003ech.qos.logback\u003c/groupId\u003e \u003cartifactId\u003elogback-classic\u003c/artifactId\u003e \u003cversion\u003e1.2.3\u003c/version\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e 关于logback-access模块将在章节末进行介绍。 由于是使用slf4j日志门面，因此获取Logger的代码与前一小节一致： import org.junit.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * @author dylan * @date 2020/12/03 */ public class LogbackTest { @Test public void testQuick() { // 1.创建日志记录器对象Logger Logger logger = LoggerFactory.getLogger(LogbackTest.class); // 2.输出各等级日志，slf4j默认日志等级是DEBUG logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); // 3.使用占位符输出日志信息 logger.info(\"用户信息：{}, {}\", \"dylan\", 12); // 4.将异常信息写入日志 try { @SuppressWarnings(\"all\") int i = 1 / 0; } catch (Exception e) { logger.info(\"出现异常：\", e); } } } ","date":"2020-03-07","objectID":"/posts/log/:7:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.logback组件 Logger：日志的记录器，把它关联到应用的对应的context上后，主要用于存放日志对象，也 可以定义日志类型、级别。 Appender：用于指定日志输出的目的地，目的地可以是控制台、文件、数据库等等。 Layout：负责把事件转换成字符串，格式化的日志信息的输出。在logback中Layout对象被封装在Encoder中。 ","date":"2020-03-07","objectID":"/posts/log/:7:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.配置文件 logback会根据顺序读取以下配置文件： logback-test.xml； logback.groovy； logback.xml。 如果指定名称的配置文件均不存在，则会采用默认配置。 日志输出格式： 占位符 描述 %level 日志等级 %d{yyyy-MM-dd HH:mm:ss.SSS} 日期和时间 %c 全限定类名 %M 方法名 %L 行号 %thread 线程名称 %m 或 %msg 日志信息 %n 换行 以下配置文件包括以下Appender： ConsoleAppender：日志将在控制台输出； FileAppender：日志将在文件输出； RollingFileAppender：日志可以根据日志文件大小进行拆分与压缩。 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cconfiguration\u003e \u003c!-- 通用的日志格式，使用占位符可以引用此格式 --\u003e \u003cproperty name=\"pattern\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n\"/\u003e \u003cproperty name=\"htmlPattern\" value=\"%level%d{yyyy-MM-dd HH:mm:ss}%c%M%L%thread%m\"/\u003e \u003c!-- Level：TRACE, DEBUG, INFO, WARN, ERROR, ALL, OFF Appender: 设置日志信息的去向,常用的有以下几个 1. ch.qos.logback.core.ConsoleAppender (控制台) 2. ch.qos.logback.core.FileAppender (文件) 3. ch.qos.logback.core.rolling.RollingFileAppender (文件大小到达指定大小的时候将产生一个新文件) --\u003e \u003c!-- 控制台输出对象ConsoleAppender配置 --\u003e \u003cappender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003c!-- 输出流对象，默认System.out，更改为System.err后输出将变为红色 --\u003e \u003ctarget\u003eSystem.err\u003c/target\u003e \u003c!-- 日志格式 --\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- LevelFilter设置，有且仅会输出指定等级的日志，例如设置为INFO时，只会输出INFO的日志 --\u003e \u003cfilter class=\"ch.qos.logback.classic.filter.LevelFilter\"\u003e \u003clevel\u003eINFO\u003c/level\u003e \u003conMatch\u003eACCEPT\u003c/onMatch\u003e \u003conMismatch\u003eDENY\u003c/onMismatch\u003e \u003c/filter\u003e \u003c/appender\u003e \u003c!-- 文件输出对象FileAppender配置，使用PatternLayoutEncoder只需要提供普通日志格式，即可生成文本日志 --\u003e \u003cappender name=\"file\" class=\"ch.qos.logback.core.FileAppender\"\u003e \u003c!-- 日志格式 --\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- 日志输出路径--\u003e \u003cfile\u003e/logback.log\u003c/file\u003e \u003c/appender\u003e \u003c!-- 文件输出对象FileAppender配置，使用LayoutWrappingEncoder并配置日志的HTML格式，日志文件将以HTML格式生成 --\u003e \u003cappender name=\"htmlFile\" class=\"ch.qos.logback.core.FileAppender\"\u003e \u003c!-- 日志格式 --\u003e \u003cencoder class=\"ch.qos.logback.core.encoder.LayoutWrappingEncoder\"\u003e \u003clayout class=\"ch.qos.logback.classic.html.HTMLLayout\"\u003e \u003cpattern\u003e${htmlPattern}\u003c/pattern\u003e \u003c/layout\u003e \u003c/encoder\u003e \u003c!-- 日志输出 --\u003e \u003cfile\u003e/logback.html\u003c/file\u003e \u003c/appender\u003e \u003c!-- 日志文件拆分与归档对象RollingFileAppender配置 --\u003e \u003cappender name=\"rollFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"\u003e \u003c!-- 日志格式 --\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c!-- 日志输出路径 --\u003e \u003cfile\u003e/roll_logback.log\u003c/file\u003e \u003c!-- 指定日志文件拆分与归档规则 --\u003e \u003crollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"\u003e \u003c!-- 当单个日志文件roll_logback.log大小到达1MB后，文件将进行压缩，roll_logback.log日志将重新开始记录 --\u003e \u003cmaxFileSize\u003e1MB\u003c/maxFileSize\u003e \u003c!-- 通过指定压缩文件名称，来确定压缩文件的命名方式，该名称也作为日志文件的名称，%i占位符默认从0开始以+1的方式自增 --\u003e \u003cfileNamePattern\u003e/rolling.%d{yyyy-MM-dd}.log%i.gz\u003c/fileNamePattern\u003e \u003c/rollingPolicy\u003e \u003c/appender\u003e \u003c!-- 如果需要设置某一个包或者具体的某一个类的日志打印级别或指定它所使用的appender，可以使用\u003clogger\u003e标签。 标签\u003clogger\u003e仅包含三个属性，其中name为必选属性，而level和additivity为可选属性。 1. name：用来指定受此logger约束的某一个包或者某一个类； 2. level：用来设置日志级别，大小写无关，如果未设置此属性，那么当前logger将会继承父日志的日志级别； 3. additivity：默认值true。是否使用父日志的appender，为false时仅logger中的appender生效。 标签\u003clogger\u003e可以包含零个或多个\u003cappender-ref\u003e标签，该标签用于指定该logger的appender。 --\u003e \u003clogger name=\"cn.hanna\" level=\"warn\" additivity=\"true\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c/logger\u003e \u003c!-- 标签\u003croot\u003e表示rootLogger对象，和\u003clogger\u003e标签一样，但只有一个可选属性level，用于设置日志级别，默认级别为debug。 标签\u003croot\u003e可以包含零个或多个\u003cappender-ref\u003e标签，该标签用于指定该logger的appender。 注意：logger与rootLogger的日志等级是以较高的为准，但存在特例。当rootLogger的等级为OFF，而logger等级为INFO时， logger的日志输出情况与rootLogger的日志等级为ALL时一致，即无法通过关闭rootLogger的日志去间接关闭logger的日志。 --\u003e \u003croot level=\"ALL\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003cappender-ref ref=\"file\"/\u003e \u003cappender-ref ref=\"htmlFile\"/\u003e \u003cappender-ref ref=\"rollFile\"/\u003e \u003c/root\u003e \u003c/configuration\u003e 注意，普通Logger与RootLogger的日志等级是以较高的为准，但存在特例。 当RootLogger的等级为OFF，而普通Logger等级为INFO时，Logger的日志输出情况与RootLogger的日志等级为ALL时一致。即无法通过关闭RootLogger的日志去间接关闭Logger的日志。 Filter标签中的LevelFilter，如果进行了配置，则仅支持指定等级的日志输出。 测试代码： import org.junit.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * @author dylan * @date 2020/12/03 */ public class LogbackTest { @Test public v","date":"2020-03-07","objectID":"/posts/log/:7:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"5.异步日志 此前所有的日志输出都是同步的，使用logback提供的异步日志，可以增加日志的输出效率，需要使用AsyncAppender将其他的Appender设置为异步形式输出日志。 可以将某一个appender设置为异步日志，参考以下配置文件： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cconfiguration\u003e \u003cproperty name=\"pattern\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n\"/\u003e \u003cappender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003ctarget\u003eSystem.err\u003c/target\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003cappender name=\"file\" class=\"ch.qos.logback.core.FileAppender\"\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003cfile\u003e/logback.log\u003c/file\u003e \u003c/appender\u003e \u003c!-- 异步日志 --\u003e \u003cappender name=\"async\" class=\"ch.qos.logback.classic.AsyncAppender\"\u003e \u003cappender-ref ref=\"file\"/\u003e \u003c/appender\u003e \u003croot level=\"ALL\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c!-- 激活异步功能 --\u003e \u003cappender-ref ref=\"async\"/\u003e \u003c/root\u003e \u003c/configuration\u003e ","date":"2020-03-07","objectID":"/posts/log/:7:5","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"6.log-access模块 logback-access模块与Servlet容器（如Tomcat和Jetty）集成，以提供HTTP访问日志功能。 我们可以使用logback-access模块来替换tomcat的访问日志，作为了解即可。不再赘述。 ","date":"2020-03-07","objectID":"/posts/log/:7:6","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"日志实现Log4j2 Apache Log4j 2是对Log4j的升级版，参考了logback的一些优秀的设计，并且修复了一些问题，带来了一些重大的提升： 异常处理，在logback中，Appender中的异常不会被应用感知到，但是在log4j2中，提供了一些异常处理机制； 性能提升， log4j2相较于log4j和logback都具有很明显的性能提升； 自动重载配置，参考了logback的设计，当然会提供自动刷新参数配置，最实用的就是我们在生产上可以动态的修改日志的级别而不需要重启应用； 无垃圾机制，log4j2在大部分情况下，都可以使用其设计的一套无垃圾机制，避免频繁的日志收集导致的jvm gc。 ","date":"2020-03-07","objectID":"/posts/log/:8:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.日志级别 Log4j2提供了5个日志级别，分别是： ERROR：错误信息，不会影响系统运行； WARN：警告信息，可能会发生问题； INFO：运行信息，数据连接、网络连接、I/O操作等等； DEBUG：调试信息，一般在开发中使用，记录程序变量参数传递信息等等。默认级别； TRACE：追踪信息，记录程序所有的流程信息。 ","date":"2020-03-07","objectID":"/posts/log/:8:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.入门案例 使用Maven项目作为示例，单纯使用log4j2，仅需添加依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-core\u003c/artifactId\u003e \u003cversion\u003e2.13.3\u003c/version\u003e \u003c/dependency\u003e 此时，获取日志记录对象Logger的方式，使用的是log4j2提供的API，调用LogManager中的静态方法getLogger()即可。 测试代码： import org.junit.Test; import org.apache.logging.log4j.Logger; import org.apache.logging.log4j.LogManager; /** * @author dylan */ public class Log4j2Test { @Test public void testQuick() { // 1.创建日志记录器对象Logger Logger logger = LogManager.getLogger(Log4j2Test.class); // 2.输出各等级日志，log4j2默认日志等级是ERROR logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); // 3.使用占位符输出日志信息 logger.info(\"用户信息：{}, {}\", \"dylan\", 12); // 4.将异常信息写入日志 try { @SuppressWarnings(\"all\") int i = 1 / 0; } catch (Exception e) { logger.info(\"出现异常：\", e); } } } 但实际上，通常会使用日志门面slf4j配合log4j2的形式，添加slf4j适配器可以实现连接，如下： \u003cdependency\u003e \u003cgroupId\u003eorg.slf4j\u003c/groupId\u003e \u003cartifactId\u003eslf4j-api\u003c/artifactId\u003e \u003cversion\u003e1.7.30\u003c/version\u003e \u003c/dependency\u003e \u003c!-- slf4j绑定log4j2 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-slf4j-impl\u003c/artifactId\u003e \u003cversion\u003e2.13.3\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.logging.log4j\u003c/groupId\u003e \u003cartifactId\u003elog4j-core\u003c/artifactId\u003e \u003cversion\u003e2.13.3\u003c/version\u003e \u003c/dependency\u003e 现在可以使用slf4j的API操作log4j2了，示例代码： import org.junit.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * @author dylan * @date 2020/12/03 */ public class Log4j2Test { @Test public void testQuick() { // 1.创建日志记录器对象Logger Logger logger = LoggerFactory.getLogger(Log4j2Test.class); // 2.输出各等级日志，log4j2默认日志等级是ERROR logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); // 3.使用占位符输出日志信息 logger.info(\"用户信息：{}, {}\", \"dylan\", 12); // 4.将异常信息写入日志 try { @SuppressWarnings(\"all\") int i = 1 / 0; } catch (Exception e) { logger.info(\"出现异常：\", e); } } } ","date":"2020-03-07","objectID":"/posts/log/:8:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.配置文件 由于log4j2是参考logback设置的，因此其中的组件基本相同，配置文件也大同小异。唯一需要注意的是ThresholdFilter，该过滤器是会保留level等级及其以上等级的日志信息。 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- status：日志实现本身的日志输出等级； monitorInterval：自动重新载入配置文件的时间间隔。 --\u003e \u003cConfiguration status=\"OFF\" monitorInterval=\"5\"\u003e \u003cproperties\u003e \u003cproperty name=\"pattern\"\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%-5level] %l%c - %m%n\u003c/property\u003e \u003cproperty name=\"filePattern\"\u003ed:/logs/$${date:yyyy-MM-dd}/rolling-%d{yyyy-MM-dd HH-mm-ss}-%i.log\u003c/property\u003e \u003cproperty name=\"logFile\"\u003ed:/logs\u003c/property\u003e \u003c/properties\u003e \u003cAppenders\u003e \u003c!-- 控制台输出日志 --\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\"\u003e \u003cPatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] [%-5level] %c:%L - %m%n\"/\u003e \u003c/Console\u003e \u003c!-- 文件输出日志 --\u003e \u003c!-- 关于ThresholdFilter中的等级level，指的是接受该等级或以上等级日志的输出，和logback中的levelFilter不太一样 --\u003e \u003cFile name=\"file\" fileName=\"${logFile}/log4j2.log\"\u003e \u003cThresholdFilter level=\"DEBUG\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003cPatternLayout pattern=\"${pattern}\"/\u003e \u003c/File\u003e \u003c!-- 文件输出日志，但使用随机读写流，性能提高 --\u003e \u003cRandomAccessFile name=\"accessFile\" fileName=\"${logFile}/log4j2-acc.log\"\u003e \u003cPatternLayout pattern=\"${pattern}\"/\u003e \u003c/RandomAccessFile\u003e \u003c!-- 文件输出，但会根据一定的规则将文件进行拆分与归档，需要压缩则将filePattern的后缀改为压缩文件后缀。 关于filePattern：/$${date:yyyy-MM-dd}/rolling-%d{yyyy-MM-dd HH-mm-ss}-%i.log 解析：是以天为单位创建文件夹，以秒为单位创建.log文件 --\u003e \u003cRollingFile name=\"rollingFile\" fileName=\"${logFile}/log4j2-rolling.log\" filePattern=\"${filePattern}\"\u003e \u003cPatternLayout pattern=\"${pattern}\"/\u003e \u003cPolicies\u003e \u003c!-- 在系统启动时，触发拆分规则，产生新的日志文件，可以省略此标签 --\u003e \u003cOnStartupTriggeringPolicy/\u003e \u003c!-- 按照文件大小拆分，设置拆分大小，可以不被包裹在\u003cPolicies\u003e标签中使用 --\u003e \u003cSizeBasedTriggeringPolicy size=\"10MB\"/\u003e \u003c!-- 按照时间节点拆分，已经根据filePattern配置，可以省略此标签 --\u003e \u003cTimeBasedTriggeringPolicy/\u003e \u003c/Policies\u003e \u003c!-- 指定在同一个目录下文件的最大个数，如果超过则会根据时间进行覆盖，防止文件日志过多 --\u003e \u003cDefaultRolloverStrategy max=\"30\"/\u003e \u003c/RollingFile\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003c!-- 配置rootLogger的日志级别和appender类型--\u003e \u003cRoot level=\"TRACE\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003cAppenderRef ref=\"file\"/\u003e \u003cAppenderRef ref=\"accessFile\"/\u003e \u003cAppenderRef ref=\"rollingFile\"/\u003e \u003c/Root\u003e \u003c!-- 配置自定义logger中的日志级别和appender，属性、子标签的配置与logback一致--\u003e \u003clogger name=\"cn.hanna\" level=\"WARN\" additivity=\"false\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c/logger\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e 测试代码如下： import org.junit.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; /** * @author dylan * @date 2020/12/03 */ public class Log4j2Test { @Test public void testQuick() { // 1.创建日志记录器对象Logger Logger logger = LoggerFactory.getLogger(Log4j2Test.class); // 2.输出各等级日志，log4j2默认日志等级是ERROR logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); // 3.使用占位符输出日志信息 logger.info(\"用户信息：{}, {}\", \"dylan\", 12); // 4.将异常信息写入日志 try { @SuppressWarnings(\"all\") int i = 1 / 0; } catch (Exception e) { logger.info(\"出现异常：\", e); } } @Test public void testLogger() { // 1.创建日志记录器对象Logger Logger logger = LoggerFactory.getLogger(\"cn.hanna\"); // 2.cn.hanna的默认输出等级为WARN，该logger的appender为Console logger.error(\"ERROR\"); logger.warn(\"WARN\"); logger.info(\"INFO\"); logger.debug(\"DEBUG\"); logger.trace(\"TRACE\"); } } ","date":"2020-03-07","objectID":"/posts/log/:8:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.异步日志 log4j2在异步日志上有较大的提升，主要得益于采用了AsyncLogger的方式，大大提高了异步日志的性能。 Async Throughput Comparison\"\rAsync Throughput Comparison\r log4j2支持两种种异步日志的实现，有： AsyncAppender：和logback中的异步日志形式一致，采用appender异步的方式实现； AsyncLogger：在logger层面上实现的异步日志。 AsyncLogger可以进一步细分为两种： AsyncLogger全局异步：使所有的logger都采用异步的方式进行输出，通过log4j2.component.properties配置，不需要更改原配置文件的设置； AsyncLogger局部异步：使部分logger采用异步的方式进行输出，通过修改log4j2.properties设置实现。 AsyncAppender和AsyncLogger同时使用时，性能与单独使用AsyncAppender时一致，因此更推荐使用AsyncLogger。 🌟4|a.AsyncAppender 通过在标签\u003cAppenders\u003e中添加子标签\u003cAsync\u003e，可以将以配置好的appender设置为异步的appender： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cConfiguration status=\"OFF\" monitorInterval=\"5\"\u003e \u003cproperties\u003e \u003cproperty name=\"pattern\"\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%-5level] %l%c{36} - %m%n\u003c/property\u003e \u003cproperty name=\"logFile\"\u003ed:/logs\u003c/property\u003e \u003c/properties\u003e \u003cAppenders\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\"\u003e \u003cPatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] [%-5level] %c{36}:%L - %m%n\"/\u003e \u003c/Console\u003e \u003cFile name=\"file\" fileName=\"${logFile}/log4j2.log\"\u003e \u003cThresholdFilter level=\"DEBUG\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003cPatternLayout pattern=\"${pattern}\"/\u003e \u003c/File\u003e \u003c!-- 异步日志 --\u003e \u003cAsync name=\"async\"\u003e \u003cAppenderRef ref=\"file\"/\u003e \u003c/Async\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003cRoot level=\"TRACE\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003c!-- 激活异步功能 --\u003e \u003cAppenderRef ref=\"async\"/\u003e \u003c/Root\u003e \u003cLogger name=\"cn.hanna\" level=\"WARN\" additivity=\"false\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003c/Logger\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e 🌟4|b.AsyncLogger/全局异步 采用异步logger的形式，需要额外添加一个依赖： \u003cdependency\u003e \u003cgroupId\u003ecom.lmax\u003c/groupId\u003e \u003cartifactId\u003edisruptor\u003c/artifactId\u003e \u003cversion\u003e3.3.4\u003c/version\u003e \u003c/dependency\u003e 配置全局异步，不需要改动原本的配置文件，额外添加一个log4j2.component.properties的配置文件即可： # log4j2全局异步配置，当使用局部异步时，此文件不能共存 Log4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector 🌟4|c.AsyncLogger/局部异步 多数情况下会使用局部异步的方式，此时全局异步必须关闭，否则局部异步无法生效。 采用异步logger的形式，需要额外添加一个依赖： \u003cdependency\u003e \u003cgroupId\u003ecom.lmax\u003c/groupId\u003e \u003cartifactId\u003edisruptor\u003c/artifactId\u003e \u003cversion\u003e3.3.4\u003c/version\u003e \u003c/dependency\u003e 通过在标签\u003cLoggers\u003e中添加子标签\u003cAsyncLogger\u003e，通过其属性可以将指定名称的logger配置成异步logger，如下： includeLocation：该属性表示是否输出行号，输出行号将降低异步日志器的性能，推荐关闭； 即使此时PatternLayout包括行号%L，也不会输出行号信息。 \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cConfiguration status=\"OFF\" monitorInterval=\"5\"\u003e \u003cproperties\u003e \u003cproperty name=\"pattern\"\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%-5level] %l%c{36} - %m%n\u003c/property\u003e \u003cproperty name=\"logFile\"\u003ed:/logs\u003c/property\u003e \u003c/properties\u003e \u003cAppenders\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\"\u003e \u003cPatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] [%-5level] %c{36}:%L - %m%n\"/\u003e \u003c/Console\u003e \u003cFile name=\"file\" fileName=\"${logFile}/log4j2.log\"\u003e \u003cThresholdFilter level=\"DEBUG\" onMatch=\"ACCEPT\" onMismatch=\"DENY\"/\u003e \u003cPatternLayout pattern=\"${pattern}\"/\u003e \u003c/File\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003cRoot level=\"TRACE\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003cAppenderRef ref=\"file\"/\u003e \u003c/Root\u003e \u003c!-- 异步logger，其中includeLocation属性为是否包含行号，是否输出行号将显著影响异步logger的性能，推荐关闭 --\u003e \u003cAsyncLogger name=\"cn.hanna\" level=\"WARN\" includeLocation=\"false\" additivity=\"false\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003c/AsyncLogger\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e ","date":"2020-03-07","objectID":"/posts/log/:8:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"5.无垃圾记录模式 log4j2自版本2.6之后，将默认开启garbage free无垃圾记录模式。在进行异步日志时，该模式有助于性能提升。 Quote\r\r无垃圾模式，官网中有如下介绍： From version 2.6, Log4j runs in “garbage free” mode by default where objects and buffers are reused and no temporary objects are allocated as much as possible. There is also a “low garbage” mode which is not completely garbage free but does not use ThreadLocal fields. This is the default mode when Log4j detects it is running in a web application. Finally, it is possible to switch off all garbage-free logic and run in “classic mode” instead. \r\r Response Time Async Logging 4 Threads\"\rResponse Time Async Logging 4 Threads\r 对于无垃圾记录模式了解即可，更多关于性能和无垃圾记录模式，可以访问以下链接： Log4j - performance Log4j - garbagefree ","date":"2020-03-07","objectID":"/posts/log/:8:5","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"SpringBoot中的日志实现 SpringBoot中使用了模块spring-boot-starter-logging用于管理日志，其结构如下： SpringBoot Logging Framework\"\rSpringBoot Logging Framework\r SpringBoot默认的日志门面是slf4j，其默认使用的日志实现是logback。简而言之，使用slf4j获取的日志记录对象，默认使用的是logback日志实现。 SpringBoot也支持使用JUL、Log4j2获取日志记录对象Logger，但由于slf4j桥接器的存在，它们最终使用logback的配置进行输出。 ","date":"2020-03-07","objectID":"/posts/log/:9:0","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"1.入门案例 SpringBoot项目的默认依赖就会导入spring-boot-starter-logging模块： \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e 项目依赖： Dependency\"\rDependency\r 测试代码： package cn.dylanphang.springbootlog; import org.junit.jupiter.api.Test; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class SpringbootLogApplicationTests { @Test void testLog4j2() { org.apache.logging.log4j.Logger logger = org.apache.logging.log4j.LogManager.getLogger(SpringbootLogApplicationTests.class); logger.info(\"Using log4j2.\"); } @Test void testJul() { java.util.logging.Logger logger = java.util.logging.Logger.getLogger(\"cn.dylanphang.springbootlog.SpringbootLogApplicationTests\"); logger.info(\"Using JUL.\"); } @Test void testLogback() { org.slf4j.Logger logger = org.slf4j.LoggerFactory.getLogger(SpringbootLogApplicationTests.class); logger.info(\"Using Logback.\"); } } testLog4j2()输出结果： log4j2\"\rlog4j2\r testJul()输出结果： JUL\"\rJUL\r testLogback()输出结果： logback\"\rlogback\r 无论使用哪种日志门面，最终都会以同一种日志形式输出。 ","date":"2020-03-07","objectID":"/posts/log/:9:1","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"2.配置文件 SpringBoot可以解析logback的配置文件，以下按解析优先度排序： 配置文件 可接受的日志实现 logback.xml logback、log4j2、JUL logback-spring.xml logback、log4j2、JUL logback.xml和logback-spring.xml的区别，在于后者是支持被SpringBoot所解析的，你可以在application.properties中，配置处于特定生产环境所需要加载的特定规则，而规则分类则添加在logback-spring.xml中。 例如，以下logback-spring.xml配置文件： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cconfiguration\u003e \u003cproperty name=\"patternDev\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level - [dev] %msg%n\"/\u003e \u003cproperty name=\"patternPro\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level - [pro] %msg%n\"/\u003e \u003cappender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003ctarget\u003eSystem.err\u003c/target\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cspringProfile name=\"dev\"\u003e \u003cpattern\u003e${patternDev}\u003c/pattern\u003e \u003c/springProfile\u003e \u003cspringProfile name=\"pro\"\u003e \u003cpattern\u003e${patternPro}\u003c/pattern\u003e \u003c/springProfile\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level=\"INFO\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c/root\u003e \u003c/configuration\u003e 此时只需要在application.properties中配置spring.profiles.active属性，即可根据dev或pro的值加载不同配置。 使用pro环境下的日志格式，则配置如下： spring.profiles.active=pro\r使用dev环境下的日志格式，则配置如下： spring.profiles.active=dev\r","date":"2020-03-07","objectID":"/posts/log/:9:2","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"3.默认配置文件 SpringBoot除了可以使用相关日志实现的配置文件外，也可以在其默认的application.properties中自定义日志配置。 当选择在application.properties中配置日志时，SpringBoot默认输出的日志文件名为Spring.log。 假如，application.properties中有以下配置： # 配置控制台输出日志的格式 logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n # 配置文件输出日志的格式及路径等 logging.file.path=d:/logs logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n logging.charset.file=UTF-8 # 为某些特定名字的logger设置日志等级，但输出的appender仍然是以上两个 logging.level.cn.hanna=trace 测试代码如下： package cn.dylanphang.springbootlog; import org.junit.jupiter.api.Test; import org.slf4j.Logger; import org.slf4j.LoggerFactory; import org.springframework.boot.test.context.SpringBootTest; @SpringBootTest class SpringbootLogApplicationTests { @Test void testLogback() { Logger logger = LoggerFactory.getLogger(SpringbootLogApplicationTests.class); logger.info(\"Using Logback.\"); Logger logger2 = LoggerFactory.getLogger(\"cn.hanna\"); logger2.trace(\"Cn hanna.\"); } } ","date":"2020-03-07","objectID":"/posts/log/:9:3","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"4.替换logback 如果希望SpringBoot的底层不使用logback，则需要改变pom.xml依赖： \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c!-- 排除原本的logging模块 --\u003e \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-logging\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e \u003c/dependency\u003e \u003c!-- 添加logj2日志模块 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-log4j2\u003c/artifactId\u003e \u003c/dependency\u003e 之后配置文件默认将识别log4j2.xml或log4j2-spring.xml，以下配置可用于测试： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003c!-- status：日志实现本身的日志输出等级； monitorInterval：自动重新载入配置文件的时间间隔。 --\u003e \u003cConfiguration status=\"OFF\" monitorInterval=\"5\"\u003e \u003cproperties\u003e \u003cproperty name=\"pattern\"\u003e[%d{yyyy-MM-dd HH:mm:ss.SSS}] [%-5level] %l%c - %m%n\u003c/property\u003e \u003c/properties\u003e \u003cAppenders\u003e \u003c!-- 控制台输出日志 --\u003e \u003cConsole name=\"console\" target=\"SYSTEM_OUT\"\u003e \u003cPatternLayout pattern=\"%d{HH:mm:ss.SSS} [%t] [%-5level] %c:%L - %m%n\"/\u003e \u003c/Console\u003e \u003c/Appenders\u003e \u003cLoggers\u003e \u003c!-- 配置rootLogger的日志级别和appender类型--\u003e \u003cRoot level=\"INFO\"\u003e \u003cAppenderRef ref=\"console\"/\u003e \u003c/Root\u003e \u003c/Loggers\u003e \u003c/Configuration\u003e ","date":"2020-03-07","objectID":"/posts/log/:9:4","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"5.注意事项 当同时存在配置文件logback.xml和application.properties时，假设存在以下配置： \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cconfiguration\u003e \u003cproperty name=\"pattern\" value=\"%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level ^ %msg%n\"/\u003e \u003cappender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"\u003e \u003ctarget\u003eSystem.err\u003c/target\u003e \u003cencoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"\u003e \u003cpattern\u003e${pattern}\u003c/pattern\u003e \u003c/encoder\u003e \u003c/appender\u003e \u003croot level=\"INFO\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c/root\u003e \u003clogger name=\"cn.hanna\" level=\"info\" additivity=\"false\"\u003e \u003cappender-ref ref=\"console\"/\u003e \u003c/logger\u003e \u003c/configuration\u003e logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n logging.file.path=d:/logs logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss.SSS} %c [%thread] %-5level %msg%n logging.charset.file=UTF-8 logging.level.cn.hanna=trace 此时，application.properties中的appender设置会被覆盖，但特定包的特定日志等级logging.level.cn.hanna=trace不会被覆盖，即使你在配置文件logback.xml中再次指定了cn.hanna的日志等级为INFO，SpringBoot会以application.properties为准。 很多规则可以通过一些简单的测试得到结论，不需要记忆太多。 ","date":"2020-03-07","objectID":"/posts/log/:9:5","tags":["Log"],"title":"Log","uri":"/posts/log/"},{"categories":["Java"],"content":"什么是JWT？ JSON Web Token是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准RFC7519。该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录SSO场景。 JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于认证，也可被加密。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:1:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"传统的Session认证 我们知道，http协议本身是一种无状态的协议，这意味着如果用户向我们的应用提供了用户名和密码用作用户认证，那么在下一次请求时，用户仍需要再一次进行用户认证。因为根据http协议，我们并不能知道是哪个用户发出的请求。 因此，为了让应用能识别是哪个用户发出的请求，我们只能在服务器存储一份用户的登录信息。这份登录信息保存在Session中，并通过Cookie的方式记录并传递该Session的JSESSIONID。 此时，已登录的用户会携带键为JSESSIONID的Cookie进行下一次请求，服务器端只需要检查指定ID的Session是否包含该用户的成功登录信息，即可完成用户的认证Authentication。 以上便是基于Session的认证操作。基于Session的认证，使应用本身很难得到扩展，随着不同客户端用户的增加，独立的服务器已经无法承载更多的用户，而这时使用基于Session认证的问题就会暴露出来。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:2:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"基于Session认证的问题 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:3:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"1.Session 每个用户经过应用认证之后，应用都要在服务端做一次记录，以方便用户下次请求的鉴别。通常而言Session都是保存在内存中的，而随着认证用户的增多，服务端的开销会明显增大。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:3:1","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"2.扩展性 用户认证之后，服务端做认证操作。如果认证的记录被保存内存中，这意味着用户下次请求必须要在保存了Session的服务器上，这样用户才能成功认证并获得相关的授权资源。这很大程度上影响了应用的扩展，如分布式系统。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:3:2","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"3.CSRF CSRF跨站请求伪造攻击，因为请求总是基于Cookie来进行用户识别与认证，此时一旦Cookie被截获，用户就很容易会受到扩展请求伪造的攻击。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:3:3","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"基于Token的授权机制 基于Token的授权机制，类似于http协议，虽然也是无状态的，但它不需要在服务器端中保留用户的认证信息或会话Session信息。这就意味着基于Token认证机制的应用，不需要考虑用户在哪一台服务器登录，为应用扩展提供了便利。 基于Token的授权的主要流程如下： Tip\r\r该Token必须要在每次请求时传递给服务器端，它应该被保存在请求头Request Header中。另外，服务器端需要指出CORS跨域资源共享策略，一般在服务器端配置Access-Control-Allow-Origin:*即可。\r\r ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:4:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"JWT的构成 JWT由三部分构成，如下表所示： Name Description header 头部，用于存储两类信息：声明类型、声明加密的算法。 payload 载荷，用于存放有效信息的部分。通常包含标准中注册的声明、公共的声明和私有的声明。 signature 签名，header和payload经过BASE64加密后的信息的字符串结合header中声明的加密方式，进一步进行加盐secret组合加密后得到的内容。 其中，secret信息是保存在服务器端的，同时JWT的签发也是在服务器端。 Warning\r\rsecret相当于服务器端的私钥，该私钥在任何场景下都不应该泄露出去。一旦用户知道该secret的值，那意味着客户端可以自行签发JWT。\r\r ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:5:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"1.头部header JWT的头部一般包含两类信息： 声明加密类型； 声明加密算法。 一个完整的header，可以表示为如下形式： { 'typ': 'JWT', 'alg': 'HS256' }。 Tip\r\rtyp表示type，即加密类型；alg表示algorithm，即加密算法。\r\r ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:5:1","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"2.载荷payload payload载荷中，一般可包含三种声明： 标准中注册的声明； 公共的声明； 私有的声明。 一个简单的payload，可以表示为如下形式： { 'sub': 'PC-77932', 'name': 'dylan', 'admin': true } 🌟2|a.标准中注册的声明（建议但不强制使用） iss：JWT签发者； sub：JWT所面向的用户； aud：接收JWT的一方； exp：JWT的过期时间，这个过期时间必须要大于签发时间； nbf：定义在什么时间之前，该JWT不可用； iat：JWT的签发时间； jti：JWT的唯一身份标识，主要用来作为一次性token，从而回避重放攻击。 🌟2|b.公共的声明 该声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息。但不建议添加敏感信息，如用户密码等，因为该部分在客户端是可以被解密的。 🌟2|c.私有的声明 该声明是提供者和消费者所共同定义的声明，同样不建议存放敏感信息，该部分也是可以在客户端被解密的。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:5:2","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"3.签名signature JWT的最后一部分为签名signature。该部分是通过拼接header与payload两部分的Base64加密字符串，并结合header中提供的加密算法及服务器中存储的指定盐salt字符串，进行加密而最终得到的密文。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:5:3","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"Maven实例 入门代码采用一个简单的Maven项目作为演示，需要在pom.xml文件中添加JWT的相关依赖： \u003cdependency\u003e \u003cgroupId\u003ecom.auth0\u003c/groupId\u003e \u003cartifactId\u003ejava-jwt\u003c/artifactId\u003e \u003cversion\u003e3.10.3\u003c/version\u003e \u003c/dependency\u003e 测试类FirstJwtTest.java源码如下，采用直接打印的方式输出结果： 其中包含了JWT对象的基本使用； 同时包含了认证token时可能会出现的异常测试。 package cn.dylanphang.jwt; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import com.auth0.jwt.exceptions.*; import com.auth0.jwt.interfaces.DecodedJWT; import org.junit.Test; import java.util.Calendar; import java.util.Date; /** * @author dylan */ @SuppressWarnings(\"all\") public class FirstJwtTest { public static final String SECRET = \"DJFOWNERO#@#$\"; @Test public void test() { // 0.date对象 final Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.SECOND, 5); // 1.签发token final String token = JWT.create() .withClaim(\"username\", \"dylan\") .withClaim(\"age\", 18) .withExpiresAt(calendar.getTime()) .sign(Algorithm.HMAC256(SECRET)); // 2.验证token final JWTVerifier verifier = JWT.require(Algorithm.HMAC256(SECRET)).build(); final DecodedJWT jwt = verifier.verify(token); // 3.获取token中的信息 System.out.println(\"username: \" + jwt.getClaim(\"username\").asString()); System.out.println(\"age: \" + jwt.getClaim(\"age\").asInt()); System.out.println(\"expireAt: \" + jwt.getExpiresAt()); } @Test public void testVerify() throws InterruptedException { // *.date对象 final Calendar calendar = Calendar.getInstance(); calendar.add(Calendar.SECOND, 5); final Date startTime = calendar.getTime(); calendar.add(Calendar.SECOND, 5); final Date endTime = calendar.getTime(); // *.签发token final String token = JWT.create() .withClaim(\"username\", \"dylan\") // payload中存放的数据 .withNotBefore(startTime) // 5秒后启用 .withExpiresAt(endTime) // 10秒后启用 .sign(Algorithm.HMAC256(SECRET)); // token采用的加密算法 // 1.token未启用，尝试认证，产生InvalidClaimException异常 this.verify(token, Algorithm.HMAC256(SECRET)); Thread.sleep(6000); // 2.伪造token或提供不一致的盐salt，产生SignatureVerificationException异常 this.verify(token, Algorithm.HMAC256(SECRET + \"d\")); // 3.提供非加密的算法，产生AlgorithmMismatchException异常 this.verify(token, Algorithm.HMAC384(SECRET)); // 4.提供非法的token，产生JWTDecodeException异常 final String illegalToken = token.replace('.', '#'); this.verify(illegalToken, Algorithm.HMAC256(SECRET)); // 5.等待过期后测试，产生TokenExpiredException异常 Thread.sleep(6000); this.verify(token, Algorithm.HMAC256(SECRET)); } /** * 认证中会出现的异常。 * * @param token token * @param algorithm algorithm */ public void verify(String token, Algorithm algorithm) { final JWTVerifier verifier = JWT.require(algorithm).build(); try { final DecodedJWT jwt = verifier.verify(token); } catch (InvalidClaimException e) { System.out.println(\"失效的payload。\"); } catch (SignatureVerificationException e) { System.out.println(\"签名认证失败。\"); } catch (AlgorithmMismatchException e) { System.out.println(\"加密算法不一致。\"); } catch (JWTDecodeException e) { System.out.println(\"非法的Token。\"); } catch (TokenExpiredException e) { System.out.println(\"令牌已过期。\"); } catch (Exception e) { e.printStackTrace(); } } } 方法test()测试输出： test()测试输出\"\rtest()测试输出\r 方法testVerify()测试输出： testVerify()测试输出\"\rtestVerify()测试输出\r 关于认证中出现的各种异常状态的说明，如下： Exception Type Description InvalidClaimException 服务器端签发token时，可以设置token的启用时间，如果未到启用时间却去认证token，则会出现此异常。 SignatureVerificationException 签名认证异常，该异常通常发生在token被恶意篡改或认证盐不正确的情况。 AlgorithmMismatchException 加密算法错误异常，当服务器端使用非加密算法对token进行认证时，会出现此异常。 JWTDecodeException 此异常通常发生在提供了一个非法token的情况，也就是提供的token不符合相关token的定义格式。 TokenExpiredException token过期异常，当服务器端对一个已过期的token进行认证时，将抛出此异常。 在实际开发中，可以将JWT封装为工具类： package cn.dylanphang.util; import com.auth0.jwt.JWT; import com.auth0.jwt.JWTCreator; import com.auth0.jwt.JWTVerifier; import com.auth0.jwt.algorithms.Algorithm; import com.auth0.jwt.interfaces.DecodedJWT; import java.util.Calendar; import java.util.Map; /** * @author dylan */ @SuppressWarnings(\"All\") public class JWTUtils { public static final String SALT = \"#\u0026HEO#^$KF(^(@#HN\"; /** * 方法的形参为payload中的数据。 * * @param map map * @return token */ public static String getToken(Map\u003cSt","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:6:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"关于信息安全的建议 不应该在JWT中的payload部分存放敏感信息； 关于盐加密中的盐salt（或secret）不能泄露，该密钥只能够保存在服务器端； 如果可以，尽量使用https协议。 ","date":"2020-01-21","objectID":"/posts/jwt_tutorial/:7:0","tags":["Security","JWT"],"title":"JWT Tutorial","uri":"/posts/jwt_tutorial/"},{"categories":["Java"],"content":"Git配置的作用范围 命令git config中的首位参数，用于指定编辑或查看的配置文件，以Windows系统为例，该配置文件存在五种形式： --global：使用全局配置文件，默认不存在全局配置文件，只有手动配置时会新增该配置文件； --system：使用系统配置文件，默认使用的配置文件，所有默认的配置都存在于该配置文件中； --local：使用本地仓库配置文件，随着仓库的克隆或初始化而存在的配置文件； --worktree：使用每个工作树的配置文件，不常用； --file \u003cfile\u003e, -f：使用指定的配置文件，不常用。 其中，配置文件中配置的生效优先级是从小到大的。 例如，global和local中均配置了credential.helper，前者为cache模式，后者为store模式。 由于配置生效优先级的存在，此时生效的是local中的配置，local的生效优先级大于global。 ","date":"2019-10-03","objectID":"/posts/git-configuration/:1:0","tags":["Git"],"title":"Git Configuration","uri":"/posts/git-configuration/"},{"categories":["Java"],"content":"配置文件的路径 仅挑选global、system和local三种配置进行说明，worktree和file配置不常被使用。 global：全局配置，该配置文件路径为：~/.gitconfig，默认情况下不存在全局配置； system：系统配置，该配置文件的路径为：$(prefix)/etc/gitconfig，该配置文件中的$(prefix)表示的是Git软件所在的目录； local：本地配置，该配置文件的路径为：$GIT_DIR/config，该配置文件中的$GIT_DIR表示的是Git仓库中.git目录。 ","date":"2019-10-03","objectID":"/posts/git-configuration/:2:0","tags":["Git"],"title":"Git Configuration","uri":"/posts/git-configuration/"},{"categories":["Java"],"content":"基本配置 对于Git仓库来说，最重要的基本配置为： user.email：用户邮箱地址； user.name：用户名称。 这两条信息用于判定你的身份，即使在用户名存在同名的情况下，也可以通过不同的邮箱地址来准确判定提交者的身份。 系统默认情况下，会推荐你使用以下的命令进行邮箱地址、用户名称的配置： git config --global user.email \"you@example.com\" git config --global user.name \"Your Name\" 以上配置将写入全局配置中。事实上你还可以将邮箱地址、用户名称配置在系统配置中： git config --system user.email \"you@example.com\" git config --system user.name \"Your Name\" 但是！并不推荐将邮箱地址、用户名称配置在本地配置中，因为本地配置即等同于Git仓库配置，该配置将写入当前仓库中的.git目录中，该目录会跟随仓库的clone或pull操作被同步到本地，如果是多人协作的项目，则可能会导致提交者信息紊乱的问题： 如果你将私人的信息配置到本地配置中，那么随着下一次的push操作，带有你私人信息的.git目录会一同被push到远程仓库中； 一旦有其他协作者clone或pull了该仓库，由于生效优先级的存在，即使该协作者存在全局的私人信息，也会被当前仓库中.git目录内本地配置的私人信息所覆盖，最终导致提交者信息出现紊乱。 因此，对于配置来说，共享配置应该写入本地配置中，而非共享配置则应该选择性写入全局配置或系统配置中。 例如默认推送分支配置，该配置会被写入到本地配置中，所有成员都会共享，这也是为什么你可以轻松使用一些Git GUI一键将本地仓库推送到远程仓库中。因为当前分支所配置的默认的推送分支，已经写在了本地配置中，且所有成员都共享这些配置。 所以，一般情况下也不推荐你更改协作项目中的本地配置。只有项目归属于私人的情况下，可以将邮箱地址、用户名称配置到本地配置中。 ","date":"2019-10-03","objectID":"/posts/git-configuration/:3:0","tags":["Git"],"title":"Git Configuration","uri":"/posts/git-configuration/"},{"categories":["Java"],"content":"查看配置信息 可以在Git Bash中使用命令，查看配置的详情： #查看全局配置 git config --global -l #查看系统配置 git config --system -l #查看本地配置 git config --local -l 如果你希望查看所有的配置，可以不添加配置范围的参数： git confing -l 以上命令会将全局配置、系统配置和本地配置的所有明细列举出来。 ","date":"2019-10-03","objectID":"/posts/git-configuration/:4:0","tags":["Git"],"title":"Git Configuration","uri":"/posts/git-configuration/"},{"categories":["Java"],"content":"什么是版本控制？ 什么是“版本控制”？我为什么要关心它呢？版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 如果你是位图形或网页设计师，可能会需要保存某一幅图片或页面布局文件的所有修订版本（这或许是你非常渴望拥有的功能），采用Version Controll System版本控制系统是个明智的选择。 有了它你就可以将选定的文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 Note\r\r使用版本控制系统通常还意味着，就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子。但额外增加的工作量却微乎其微。\r\r ","date":"2019-09-21","objectID":"/posts/git/:1:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"编程中的版本控制 在编程中，版本控制Revision Control是一种在开发过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份以便恢复以前的版本的软件工程技术，简单地说，就是用于管理多人协同开发项目的技术。 实现跨区域多人协同开发 跟踪和记载一个或者多个文件的历史记录 组织和保护你的源代码和文档 统计工作量 并行开发、提高开发效率 跟踪记录整个软件的开发过程 减轻开发人员的负担，节省时间，同时减低认为错误 Project without VCS\r\r没有进行版本控制或者版本控制本身缺乏正确的流程管理，在软件开发过程中将会导致很多问题的发生，如软件代码的一致性、软件内容的冗余、软件过程的事务性、软件开发过程中的并发性、软件源代码的安全性，以及软件的整合等问题。\r\r ","date":"2019-09-21","objectID":"/posts/git/:2:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"什么是Git？ Git是一个开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。Git是Linus Torvalds为了帮助管理Linux内核开发而开发的一个开放源码的版本控制软件。 Git与常用的版本控制工具CVS、Subversion等不同，它采用了分布式版本库的方式，不需要服务器端软件的支持。 Common VCSs\r\r市面上锁常见的版本控制器，有如下几个： Git SVN（Subversion） CVS（Concurent Versions System） VSS（Microsoft Visual SourceSafe） TFS（Team Foundation Server） Visual Studio Online \r\r Difference between Git and SVN\r\rGit和SVN区别点： Git是分布式的，SVN不是。这是Git与其它非分布式的版本控制系统，例如SVN、CVS等，最核心的区别； Git把内容按元数据方式存储，而SVN是按文件。所有的资源控制系统都是把文件的元信息隐藏在一个类似**.svn**、**.cvs**这样的目录中； Git分支和SVN的分支不同。分支在SVN中一点都不特别，其实它就是版本库中的另外一个目录； Git没有一个全局的版本号，而SVN有。目前为止，这是跟SVN相比Git缺少的最大的一个特征； Git的内容完整性要优于SVN。Git的内容存储使用的是SHA-1哈希算法，这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时，降低对版本库的破坏。 \r\r SVN资源库与Git资源库\"\rSVN资源库与Git资源库\r ","date":"2019-09-21","objectID":"/posts/git/:3:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git的特点 Git的特点可以总结为四个： Git存储项目随时间改变的快照； Git中绝大多数操作都是本地进行的； Git的特殊数据校验机制，保证了数据的完整性； Git在多数情况下进行的都是写操作，操作一旦提交，则难以丢失。 ","date":"2019-09-21","objectID":"/posts/git/:4:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.记录快照 Git和其他版本控制系统（包括Subversion和近似工具）的主要差别在于Git对待数据的方式。 从概念上讲，其他大部分系统以文件变更列表的方式存储信息，这类系统（CVS、Subversion、Perforce、Bazaar等等）将它们存储的信息看作是一组基本文件和每个文件随时间逐步积累的差异（它们通常被称作基于差异delta-based的版本控制）。 基于差异delta-based的版本控制\"\r基于差异delta-based的版本控制\r Git不按照以上方式对待或保存数据。反之，Git更像是把数据看作是对小型文件系统的一些列快照。 Git存储项目随时间改变的快照，这是Git与几乎所有其他版本控制系统的重要区别。它更像是一个小型的文件系统，提供了许多以此为基础构建的超强工具，而不是一个简单的VCS。 Git存储项目随时间改变的快照\"\rGit存储项目随时间改变的快照\r 每当你提交更新或保存项目状态时，Git就会对当时的全部文件创建一个快照并保存这个快照的索引。为了效率，如果文件没有修改，Git不在重新存储该文件，而是只保留一个链接指向之前存储的文件。Git对待数据更像是一个快照流。 ","date":"2019-09-21","objectID":"/posts/git/:4:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.本地执行操作 Git中的绝大多数操作都只需要访问本地文件和资源，一般不需要来自网络上其它计算机的信息。如果你习惯于所有操作都有网络延时开销的集中式版本控制系统，Git在这方面会让你感到效率的飙升。因为在本地磁盘上就有项目的完整历史，所以大部分操作看起来都是瞬间完成的。 Example\r\r如果需要浏览项目的历史，Git不需外连接到服务器去获取历史，它只需直接从本地数据库中读取，你能立即看到项目历史记录。 如果你想查看当前版本与一个月前的版本之间引入的修改，Git会查找到一个月前的文件做一次本地的差异计算，而不是由远程服务器处理或从远程服务器拉回旧版本文件再来本地处理。 \r\r 本地执行操作也意味着你在离线或者没有VPN时，几乎可以进行任何操作。 如果你在飞机或火车上想做些工作，可以愉快地将项目提交到本地仓库，直到有网络连接时再进行上传。而使用其它版本控制系统的话，做到这些是不可能或是很费力的。 Info\r\r在无网络的情况下，使用Perforce的话，没有连接服务器时几乎不能做什么事；而使用Subversion和CVS的话，允许修改文件，但无法向数据库提交修改，因为本地数据库离线了。\r\r ","date":"2019-09-21","objectID":"/posts/git/:4:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"3.数据完整性 Git中所有的数据在存储前都进行计算校验和，然后以校验和来引用。任何位置都不可能在Git不知情时，更改任何文件内容或目录内容。这个功能建构在Git底层，是构成Git哲学不可或缺的部分。若你在传送过程中丢失信息或损坏文件，Git一定能发现。 SHA-1 Hash\r\rGit用以计算校验和的机制叫做SHA-1散列（hash，哈希）。 这是一个由四十个十六进制字符组成的字符串，基于Git中文件的内容或目录结构计算出来。Git中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。SHA-1哈希看起来是这样的： 24b9da6552252987aa493b52f8696cd6d3b00373 \r\r ","date":"2019-09-21","objectID":"/posts/git/:4:3","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"4.数据持久性 你执行的Git操作，几乎只往Git数据库中添加数据。你很难让Git执行任何不可逆操作，或者让它以任何方式清除数据。 与其他VCS一样，未提交更新时有可能丢失或弄乱修改的内容。但一旦你提交快照到Git中，就难以再丢失数据，特别是如果你定期的推送数据到远程仓库的话。 ","date":"2019-09-21","objectID":"/posts/git/:4:4","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"版本控制的种类 根据设计与应用理念的不同，可以将版本控制分类为： 本地版本控制； 集中版本控制； 分布式版本控制。 ","date":"2019-09-21","objectID":"/posts/git/:5:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.本地版本控制 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。 本地版本控制\"\r本地版本控制\r 其中最流行的一种叫做RCS，现今许多计算机系统上都还看得到它的踪影。RCS的工作原理是在硬盘上保存补丁集（补丁是指文件修订前后的变化）；通过应用所有的补丁，可以重新计算出各个版本的文件内容。 ","date":"2019-09-21","objectID":"/posts/git/:5:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.集中版本控制 接下来，人们又遇到一个问题，如何让在不同系统上的开发者协同工作？ 于是，集中化的版本控制系统（Centralized Version Control Systems，简称 CVCS）应运而生。 这类系统，诸如 CVS、Subversion 以及Perforce等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。 多年以来，这已成为版本控制系统的标准做法。 集中化版本控制\"\r集中化版本控制\r 这种做法带来了许多好处，特别是相较于老式的本地VCS来说。现在，每个人都可以在一定程度上看到项目中的其他人正在做些什么。管理员也可以轻松掌控每个开发者的权限，且管理一个CVCS要远比在各个客户端上维护本地数据库来得轻松容易。 事分两面，有好有坏。这么做最显而易见的缺点是中央服务器的单点故障。 如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。如果中心数据库所在的磁盘发生损坏，又没有做恰当备份，毫无疑问你将丢失所有数据——包括项目的整个变更历史，只剩下人们在各自机器上保留的单独快照。 本地版本控制系统也存在类似问题，只要整个项目的历史记录被保存在单一位置，就有丢失所有历史更新记录的风险。 ","date":"2019-09-21","objectID":"/posts/git/:5:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"3.分布式版本控制 于是，分布式版本控制系统（Distributed Version Control System，简称DVCS）应运而生。在这类系统中，像Git、Mercurial、Bazaar 以及Darcs等，客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来，包括完整的历史记录。 这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的克隆操作，实际上都是一次对代码仓库的完整备份。 分布式版本控制\"\r分布式版本控制\r 更进一步，许多这类系统都可以指定和若干不同的远端代码仓库进行交互。籍此，你就可以在同一个项目中，分别和不同工作小组的人相互协作。 你可以根据需要设定不同的协作流程，比如层次模型式的工作流，而这在以前的集中式系统中是无法实现的。 ","date":"2019-09-21","objectID":"/posts/git/:5:3","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"文件状态与工作阶段 如果你使用Git作为项目或文档的版本控制系统，那么对应项目或文档中的所有文件，必然会处于某种Git所规定的状态下，同时对应状态的文件，必然处于Git所规定的某种阶段内。 ","date":"2019-09-21","objectID":"/posts/git/:6:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.文件状态 Git中的文件有三种状态，你的文件可能处于其中之一： modified：已修改状态，表示修改了文件，但还没有保存到数据库中； staged：已暂存状态，表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中； committed：已提交状态，表示数据已经安全地保存在本地数据库中。 Tip\r\r处于modified、staged、committed状态的文件，是指纳入了版本控制的文件。简而言之，就是Git已经知道的文件，这些文件被统称为tracked已跟踪文件。 而工作区中Git所不知道的文件，被统称为untracked未跟踪文件。 \r\r ","date":"2019-09-21","objectID":"/posts/git/:6:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.工作阶段 Git中文件的三种状态，分别对应着该文件所处于的阶段： 工作区、暂存区以及Git目录\"\r工作区、暂存区以及Git目录\r Working Directory：工作区； Staging Area：暂存区； Repository：本地仓库。 Info\r\r如果Git目录（本地仓库）中保存着特定版本的文件，就属于committed已提交状态。如果文件已修改并放入暂存区，就属于staged已暂存状态。如果自上次检出后，作了修改但还没有放到暂存区域，就是modified已修改状态。\r\r Git Workflow\r\r使用Git作为版本控制系统，通常的使用流程如下： 在working directory工作区中修改文件； 将你想要在下次提交的更改，选择性地暂存，这样只会将更改的部分添加到staging area暂存区； 提交更新，找到暂存区的文件，将快照永久性地存储到.git directory本地仓库。 \r\r 🌟2|a.working directory（工作区） 工作区是对项目的某个版本独立提取出来的内容。这些从Git仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 🌟2|b.staging area（暂存区） 暂存区是一个文件，文件中保存了下次将要提交的文件列表信息，一般在Git仓库目录中。该文件按照Git的术语叫做“索引”，不过一般说法还是叫“暂存区”。 通常需要将modified文件转换为staged文件，会使用到以下命令： git add \u003cpathspec\u003e 🌟2|c.repository/.git directory（本地仓库） 本地仓库是Git用来保存项目的元数据和对象数据库的地方，这是Git中最重要的部分。从其他计算机克隆仓库时，复制的就是这里的数据。 通常需要将staged文件转换为committed文件，会使用到以下命令： git commit -m \u003cmsg\u003e 🌟2|d.remote repository（远程仓库） 远程仓库不是Git的一部分，但通常情况下，多人协作的项目都会具有远程仓库。使用以下命令，可以将本地仓库中的数据，推送并保存至远程仓库： git push \u003cremote\u003e \u003cbranch\u003e Tip\r\r需要注意，此处的remote所指代的就是远程仓库的连接地址。当然，如果此时具备该远程仓库的别名，也可以直接使用别名来替换remote。 其次，push命令中的第二个参数branch具有一定特殊性，该参数是local_branch:remote_branch的缩写，local_branch、remote_branch都等于branch。 \r\r Git支持为远程仓库添加别名，可以同时为多个远程仓库添加别名，添加命令如下： git remote add \u003cremote_alias\u003e \u003cremote\u003e 需要查看当前已设置别名的远程仓库列表，可以使用命令： git remote 所有已设置别名的远程仓库，都可以在当前Git仓库的配置文件中，查看到相关的信息： cat .git/config ","date":"2019-09-21","objectID":"/posts/git/:6:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"安装Git Git提供多平台的支持，获取Git的安装包，请转到：Git - Downloads。 ","date":"2019-09-21","objectID":"/posts/git/:7:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"获取Git仓库 如果希望使用Git对项目或目录进行版本控制，那么必须在当前需要进行版本控制的目录中，获取一个Git仓库。 通常有两种获取Git项目仓库的方式： 将尚未进行版本控制的本地目录转换为Git仓库； 从其它服务器克隆一个已存在的Git仓库。 ","date":"2019-09-21","objectID":"/posts/git/:8:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.初始化仓库 如果你有一个尚未进行版本控制的目录，想要用Git来控制它，那首先需要进入该项目目录中。之后执行： git init 该命令将创建一个名为.git的子目录，这个子目录含有你初始化的Git仓库中所有必须文件，这些文件是Git仓库的骨干。但是这个时候，我们仅仅是做了一个初始化的操作，你的项目你的文件还没有被跟踪。 Tip\r\r.git目录默认情况下是隐藏状态的。Windows下需要改变文件的显示规则，来显示隐藏的文件夹；Linux下通过命令ll -a，即可看到当前目录中的隐藏文件。\r\r 如果你在一个已存在的文件的文件夹（非空文件夹）中进行版本控制，你应该开始跟踪这些文件并进行初始提交。可以通过git add命令来指定所需要的文件来进行跟踪，然后执行git commit： git add . git add LICENSE git commit -m \"initial project version\" ","date":"2019-09-21","objectID":"/posts/git/:8:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.克隆现有仓库 如果你想要获得一份已存在的Git仓库拷贝，比如说，你想为某个开源项目共享自己的一分力，这时你要用的命令是git clone。 如果你对其它的VCS系统（比如说Subversion）很熟悉，请留心一下你所使用的命令是clone而不是checkout。这是Git区别于其它版本控制系统的一个重要特性，Git克隆的是该Git仓库服务器上的几乎所有数据，而不是仅仅复制完成你的工作所需要文件。 Tip\r\r在Git中，checkout命令用于分支的切换。\r\r 当你执行git clone命令的时候，默认配置下远程Git仓库中的每一个文件的每一个版本都将被拉取下来。事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库（虽然可能会丢失某些服务器端的钩子hook设置，但是所有版本的数据仍在）。 克隆仓库的命令是git clone \u003curl\u003e： git clone https://github.com/libgit2/libgit2 这条命令将在当前目录下创建一个名为libgit2的目录，并在这个目录下初始化一个.git文件夹，从远程仓库拉取所有数据放入.git文件夹，然后从中读取最新版本的文件拷贝。如果你进入这个新建的libgit2文件夹，你会发现所有的项目文件已经在里面，并准备就绪等待后续的开发和使用。 如果你想在克隆远程仓库的时候，自定义本地仓库的名字，你可以通过额外的参数指定新的目录名： git clone https://github.com/libgit2/libgit2 mylibgit 这将会执行同样的克隆操作，但创建的目标目录名变为了mylibgit。 Transfer protocol\r\rGit支持多种数据传输协议。以上例子使用的是https协议，你也可以使用git协议或者SSH协议。\r\r ","date":"2019-09-21","objectID":"/posts/git/:8:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git基本操作 获取Git仓库后，在你的working directory工作目录（工作区）下，每一个文件都不外乎是两种状态：Tracked已跟踪和Untracked未跟踪。 Tracked已跟踪状态可以进一步区分为Modified已修改、Staged已暂存和Committed已提交状态。 其中，Committed已提交状态也被视为Unmodified未修改状态。 Tracked \u0026 Untracked\r\r已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能是未修改、已修改或已放入暂存区。简而言之，已跟踪的文件就是Git已经知道的文件。 工作目录中除了已跟踪文件外的其他文件，都属于未跟踪文件，它们既不存在于上次快照记录中，也没有被放入暂存区。 \r\r 初次克隆某个仓库的时候，工作目录中的所有文件都属于Tracked已跟踪文件，并处于Unmodified未修改状态，因为Git刚刚检出了它们，而你尚未编辑过它们。 编辑过某些文件之后，由于自上次提交后你对它们做了修改，Git将它们标记为Modified已修改文件。在工作时，你可以选择性地将这些修改过的文件放入stage area暂存区，然后提交所有Staged已暂存的修改，如此反复。 Git下文件的生命周期\"\rGit下文件的生命周期\r Git提供查看当前分支下所有文件状态的命令，如下： git status 如新建的文件，其所处于的状态是untracked。git status命令会将untracked文件列举出来： touch file.txt \u0026\u0026 git status Untracked\"\rUntracked\r 当新建文件添加到暂存区预备提交时，其所处于的状态则为staged。git status命令会提示该文件准备提交： touch file.txt \u0026\u0026 git add file.txt \u0026\u0026 git status Staged\"\rStaged\r 暂存区文件被成功提交到本地仓库时，其状态变为unmodified。git status命令则不会显示已跟踪但未更改的文件： touch file.txt \u0026\u0026 git add file.txt \u0026\u0026 git commit -m 'x' \u0026\u0026 git status Unmodified\"\rUnmodified\r 而已跟踪的文件被修改后，其状态变为modified。git status命令将提示该文件已被修改但未被列入暂存区： touch file.txt \u0026\u0026 git add file.txt \u0026\u0026 git commit -m 'x' git status echo \"hey.\" \u003e\u003e file.txt \u0026\u0026 git status Modified\"\rModified\r Tip\r\r使用git status命令，还可以显示一种unmerged的文件状态。该状态出现在分支合并冲突的情况下，后续将详细讲解关于分支合并的问题。\r\r 工作中常用的Git命令，可以分为以下四类： 从远程仓库中克隆仓库或拉取项目代码； 对工作目录中的文件进行修改后，将已修改文件提交到暂存区； 将暂存区中的代码提交到本地仓库； 将本地仓库中的代码推送到远程仓库。 下图是Git基本命令作用于各种状态之后的转换图解： Git状态转换图解\"\rGit状态转换图解\r ","date":"2019-09-21","objectID":"/posts/git/:9:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.clone \u0026 pull 从远程仓库中获取数据，可能会涉及到clone命令或pull命令。 Tip\r\r无论是clone、pull/fetch命令，还是后续提及的push命令，使用它们都需要提供远程仓库的连接地址，该地址可以是http(s)或SSH等协议的链接。 http(s)协议支持匿名访问，意味着只有使用push命令时，需要提供相应的凭证进行服务器认证；而SSH协议则不支持匿名访问，这意味着无论使用push，还是clone、pull/fetch，都需要提供对应的SSH私钥进行认证。 \r\r 🌟1|a.克隆仓库 #获取Git仓库-2.克隆现有仓库中，已经讲述了如何进行仓库的克隆，以下将结合简单的例子及示例图片再作一次简要说明。 通常情况下，获取项目代码的第一个步骤，是克隆仓库，而非拉取代码。 克隆仓库需要提供连接目标仓库的http(s)协议或SSH协议的连接地址，使用以下命令即可获取到整个项目的仓库： ## Https Protocol git clone https://github.com/2phangx-dylan/example.repository.git ## SSH Protocol git clone git@github.com:2phangx-dylan/example.repository.git example.repository\"\rexample.repository\r 此时，默认仓库的名称会自动命名为远程仓库的名称。如果希望在克隆仓库的同时，重命名本地仓库的名称，可以在链接之后添加自定义的本地仓库名称参数。 ## Https Protocol git clone https://github.com/2phangx-dylan/example.repository.git my.repository ## SSH Protocol git clone git@github.com:2phangx-dylan/example.repository.git my.repository my.repository\"\rmy.repository\r 🌟1|b.拉取代码 在多人协作的情况下，需要经常进行代码的pull操作，以确保工作目录内的文件内容为最新内容。 使用pull/fetch命令时，需要提供远程仓库的连接凭证，关于不同协议所使用的凭证，请参考：#Git凭证。 但通常情况下，不推荐直接使用pull命令，你需要十分确定当前分支是需要进行合并的分支。原因是pull命令实际上是fetch命令和merge命令的整合，以下命令： git pull \u003cremote\u003e \u003cremote_branch\u003e 等同于： git fetch \u003cremote\u003e \u003cremote_branch\u003e git merge FETCH_HEAD 保险起见，应该总是首先使用fetch命令将远程仓库分支拉取到本地（该fetch的分支会被自动命名为FETCH_HEAD），之后再进行相关的merge分支合并操作。 fetch \u0026 merge\"\rfetch \u0026 merge\r 以下命令，可用于查看当前fetch的远程仓库分支（FETCH_HEAD除外）： git remote 以下命令，可用于查看、删除远程仓库分支： git branch -r git branch -rd \u003cremote_alias\u003e/\u003cremote_branch\u003e Tip\r\rremote_alias是remote远程仓库的别名，详情可以查看#Git命令简化-1.远程仓库连接别名。\r\r 初始化仓库拉取代码 如果此时你拥有的是一个初始化的仓库，此时需要拉取项目的代码，应该如何操作呢？ 显而易见，需要拉取项目代码，必须拥有连接的地址，从该地址中获取仓库数据。之后应该明确需要获取的远程仓库分支，该远程分支将在本地仓库的当前分支无任何内容的情况下，将覆盖当前分支的内容。 因此，在使用pull的方式首次获取项目数据，其步骤有四个： 初始化本地仓库； 确定远程仓库连接地址； 确定远程仓库分支； 拉取代码。 以上步骤，只需要执行两行命令，即可完成： git init git pull git@github.com:2phangx-dylan/example.repository.git main pull\"\rpull\r 其中，第二行命令，即等同于告诉Git当前仓库的master分支中的数据，需要从git@github.com:2phangx-dylan/example.repository.git中的main分支获取。 注意，此时master分支实际为空分支。当需要合并两个分支，且其中一个分支为空分支时，那么合并分支必然成功，空分支的内容将被另一个分支的内容所覆盖。 那么如果，当前仓库中的master分支存在已提交/未修改内容呢？ 尝试在初始化仓库与拉取项目代码之间，插入新建文件、添加并提交文件的代码： git init touch file.txt git add file.txt \u0026\u0026 git commit -m \"update.\" git pull git@github.com:2phangx-dylan/example.repository.git main 此时拉取代码失败，终端提示错误信息： fatal: refusing to merge unrelated histories。 pull\"\rpull\r 显然，此时本地仓库中的master分支，与远程仓库中的main分支都不为空，同时它们的分支祖先并不一致，此时的分支合并操作必然失败。 对于分支祖先不一致的情况，Git提供了一种强制合并的手段，即在拉取代码时添加--allow-unrelated-histories参数。 在添加以上参数的情况下，再次拉取项目代码： git pull --allow-unrelated-histories git@github.com:2phangx-dylan/example.repository.git main 此时代码将拉取成功，但Git Bash对话框会弹出MERGE_MSG文档，要求填写此次分支合并的log，如下图所示： MERGE_MSG\"\rMERGE_MSG\r 其中首行即为默认的log，你可以更改为自定义信息。 熟悉vim操作的话，此时双击小写字母d删除光标所在行，单击大写字母O进入插入模式，即可输入自定义的合并信息： MERGE_MSG\"\rMERGE_MSG\r 信息输入完毕后，按ESC键退出插入模式，并进入命令模式。命令模式下输入:wq保存文件即可： MERGE_MSG\"\rMERGE_MSG\r 合并信息填写并保存完毕后，非同祖先分支的合并就完成了： merge branches\"\rmerge branches\r 但不推荐合并非同祖先的分支，这没有什么意义。 Tip\r\rGit中仅有两个操作会涉及到注释信息的填写，分别是commit提交操作与merge分支合并操作。前者只要提交，就需要填写注释信息；而后者仅在出现合并冲突时，需要填写相关的注释信息。 此前说过，pull命令等同于fetch、merge命令的整合，如果pull命令需要填写相关注释，则表示分支合并出现了冲突。 \r\r 普通拉取代码 一般情况下会采用克隆仓库的方式获取项目代码，而日常则采用pull来拉取最新的代码。 Tip\r\r仍然建议使用fetch来获取远程仓库分支的本地快照，之后再进行相关的merge操作。除非你十分肯定当前的本地仓库分支是需要进行合并的分支。\r\r 关于pull命令，有如下建议： 谨慎使用pull命令，该命令会同时将远程仓库分支拉取至本地，并与当前分支进行合并； 使用fetch命令和merge命令，来替换pull命令； 在pull或merge之前，保证当前分支的整洁。 大多数情况下，使用fetch命令都是没有任何问题的，如下： git fetch \u003cremote | remote_alias\u003e \u003cremote_branch\u003e fetch只会将远程仓库分支拉取到本地。而问题一般出现在合并分支上，也就是merge操作。 如果当前分支中存在modified已修改、staged已暂存的文件，同时该文件在远程仓库中经历过了修改，那么再次使用pull命令拉取代码时，Git会报错： git pull\"\rgit pull\r 该报错正是merge命令造成的，因为merge操作出现合并冲突时，保留的一方必然是已提交的文件。那么显然，对于modified已修改、staged已暂存的文件来说，merge命令无法使用它来进行比较。 此时，只需要将导致错误的相关文件进行暂存且提交，即可修复报错： git pull\"\rgit pull\r merge命令还会带来所谓的合并冲突，远程分支与本地分支的合并、本地分支之间的合并，都可以出现合并冲突。 合并冲突只能依靠手动人工解决。关于合并冲突，可以查看：#Git分支-3.合并冲突 ","date":"2019-09-21","objectID":"/posts/git/:9:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.add 将未跟踪或已修改文件添加到暂存区预备提交时，需要使用到add命令。其使用方法十分简单： git add . git add \u003cfile_name\u003e 如果不小心将错误的文件进行了暂存，可以使用以下命令将文件从暂存区移除： git restore --staged \u003cfile_name\u003e 对应文件将从staged暂存状态恢复到untracked未追踪或modified已修改状态。 ","date":"2019-09-21","objectID":"/posts/git/:9:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"3.commit 将已暂存的文件提交到本地仓库时，需要使用到commit命令。该命令一般配合参数-m使用，用于指定提交信息： git commit -m \u003ccommit_msg\u003e 该命令总是将暂存区的所有文件，提交到本地仓库。 对于已跟踪的文件来说，如果你对它进行了修改，可以使用以下命令完成该文件的暂存与提交： git commit -a -m \u003ccommit_msg\u003e 如果直接使用commit命令，不添加任何的参数，Git会强制要求你需要对此次的提交进行注释： git commit 该命令运行后，将出现COMMIT_EDITMSG窗口，强制要求填写合并注释： COMMIT_EDITMSG\"\rCOMMIT_EDITMSG\r 因此，如果你不希望与vim命令打交道，那么最好在commit的时候都加上-m参数。 在了解完如何将暂存区文件提交到本地仓库后，你一定想知道如何从提交错误中恢复。 此前所说的Git工作阶段共有三种，分别是working directory（工作区）、staging area（暂存区）和.git directory（本地仓库）。 而reset命令中，会将暂存区视为Index索引，其中本地仓库始终有一个HEAD指向当前分支的最新一次commit提交。 reset-workflow\"\rreset-workflow\r reset命令看起来是这样的： git reset [--soft | --mixed | --hard] [\u003ccommit\u003e] Tip\r\r通过命令： git log 可以查看当前分支的所有commit记录。 \r\r 假设我们进入了一个目录，新建了一个file.txt文件，该文件版本为v1。此时文件必然位于工作区： touch file.txt\"\rtouch file.txt\r 现在我们想要提交这个文件，所以用git add来获取工作目录中的内容，并将其复制到索引中： git add file.txt\"\rgit add file.txt\r 接着运行git commit，它会取得索引中的内容并将它保存为一个永久的快照，然后创建一个指向该快照的提交对象，最后更新master来指向本次提交： git commit\"\rgit commit\r 此时如果我们运行git status，会发现没有任何改动，因为现在三棵树完全相同。 现在我们想要对文件进行修改然后提交它。我们将会经历同样的过程；首先在工作目录中修改文件。 我们称其为该文件的v2版本，并将它标记为红色： edit file\"\redit file\r 如果现在运行git status，我们会看到文件显示在Changes not staged for commit下面并被标记为红色，因为该条目在索引与工作目录之间存在不同。 接着我们运行git add来将它暂存到索引中： git add file.txt v2\"\rgit add file.txt v2\r 此时，由于索引和HEAD不同，若运行git status的话就会看到Changes to be committed下的该文件变为绿色。也就是说，现在预期的下一次提交与上一次提交不同。 最后，我们运行git commit来完成提交： git commit\"\rgit commit\r 现在运行git status会没有输出，因为三棵树又变得相同了。 Tip\r\r切换分支或克隆的过程也类似。当checkout检出一个分支时，它会修改HEAD指向新的分支引用，将Index填充为该次提交的快照，然后将Index的内容复制到working directory中。\r\r 为了展示reset命令的作用，假设我们对file.txt进行了第三次修改提交。现在历史看起来是这样的： reset start\"\rreset start\r Tip\r\rreset命令所做的第一件事是移动HEAD的指向，这与checkout命令改变HEAD的指向不同，reset移动了HEAD指向的分支。\r\r 🌟3|a.移动HEAD（–soft） 如果希望仅撤销上一次的提交，则可以使用以下命令： git reset --soft HEAD~ 该命令仅撤销上一次提交操作，此时v3版本的文件仍存在于暂存区和工作目录。 reset soft\"\rreset soft\r 🌟3|b.更新索引（–mixed） 如果想将上一次的commit撤销的同时，上一次添加到暂存区的文件也一并restore，则需要使用以下命令： git reset [--mixed] HEAD~ 此时，v3版本的文件不仅撤销了提交，也从暂存区移出，此时已修改文件仅存在于工作目录中。 🌟3|c.更新工作目录（–hard） 如果希望做得更加彻底，连同当前版本的更改也不需要保留，则可以使用以下命令： git reset --hard HEAD~ 该命令将撤销所有上一次的commit提交、add暂存和edit file更改操作。 Tip\r\r关于HEAD的说明： HEAD：当前快照、最近一次提交或当前分支； HEAD~1：当前快照之前的一个快照，即回退一个快照，可以简写为HEAD~。 HEAD~2：当前快照之前的两个快照，以此类推。 以上关键字主要用于配合reset命令使用。 除此之外，还有HEAD^、HEAD^2等关键字，这些关键字主要用于指示merge之后的回退方向，配合命令checkout使用。 \r\r ","date":"2019-09-21","objectID":"/posts/git/:9:3","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"4.push 当你希望将本地仓库推送到远程仓库时，就需要用到push命令。 使用push命令时，不仅要求提供远程仓库的连接信息，还要求提供远程仓库的认证信息。对于连接信息，就是所谓的http(s)或SSH协议的链接，不再赘述。 对于认证信息，请参阅：#Git凭证。 push命令的基本操作如下： git push \u003cremote\u003e [\u003cbranch\u003e:]\u003cbranch\u003e 该命令表示将当前所在的本地仓库分支，推送到远程仓库remote的branch分支中。 也许你已经留意到了，push命令的格式有一点奇怪。事实上，你也可以直接使用以下命令来推送数据： git push \u003cremote\u003e \u003cbranch\u003e 但该命令会被解析为： git push \u003cremote\u003e \u003clocal_branch\u003e:\u003cremote_branch\u003e 此时，local_branch、remote_branch都等于branch，需要注意： 你的远程分支如果没有remote_branch，则该remote_branch会自动在远程仓库中被新建，之后再与本地仓库的locat_branch进行合并； 你的本地分支如果没有local_branch，则命令会报错。 鉴于以上两条细节性问题，需要十分留意branch的设定，一般情况下，本地仓库分支名称与其对应的远程仓库分支名称会设置为相同的。 重命名当前分支，可以使用以下命令： git branch -m \u003cnew_branch_name\u003e 重命名任意分支，则需要额外添加一个参数： git branch -m \u003cold_branch_name\u003e \u003cnew_branch_name\u003e 从git push命令的格式也推测出，Git允许在任意的分支内，推送另一个本地分支的内容到指定的远程分支上： git push \u003cremote\u003e \u003cother_branch\u003e:\u003cremote_branch\u003e ","date":"2019-09-21","objectID":"/posts/git/:9:4","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git命令简化 Git中的某些命令总是会被经常使用到，如pull、push等。这些命令总是要求提供远程仓库的连接地址与分支名称，使用起来十分麻烦。 幸运的是，Git中提供了几种简化命令的方法。 ","date":"2019-09-21","objectID":"/posts/git/:10:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.远程仓库链接别名 给远程仓库链接设定一个别名，是简化命令最容易的手段。远程仓库链接通常是http(s)或SSH协议的地址，Git中允许给这些链接设定别名，且可以同时设置多个远程仓库。 远程仓库设定别名的命令如下： git remote add \u003cremote_alias\u003e \u003cremote\u003e remote为远程仓库连接地址，而remote_alias则为该链接的别名。 一经设定，此后在需要用到remote链接的地方，都可以使用remote_alias进行替换。 如果需要移除该别名，可以使用以下命令： git remote remove \u003cremote_alias\u003e 远程仓库别名也可以通过命令进行重命名操作，如下： git remote rename \u003cold_alias\u003e \u003cnew_alias\u003e 实际上，添加、删除或重命名远程仓库别名，是通过修改本地仓库配置文件.git/config实现的，如图所示： .git/config\"\r.git/config\r 添加remote_alias后，config文件中会生成一个键值对，其中键包含remote_alias，值则包含remote。 通过命令建立起的一一对应关系，使得Git可以通过remote_alias精准检索到remote的具体地址。 映射关系通常表明了键不可重复，而值可重复的内在含义。在Git中，remote_alias与remote的映射关系也同样如此。一个本地仓库中允许存在多个不重复的remote_alias，此时它们指向的remote被允许是相同的。 .git/config\"\r.git/config\r 最后，你可以通过以下命令查看当前的远程仓库别名列表： git remote 也可以直接查看.git/config文件，浏览所有已设置别名的远程仓库列表： cat .git/config git remote \u0026 cat .git/config\"\rgit remote \u0026 cat .git/config\r ","date":"2019-09-21","objectID":"/posts/git/:10:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.push默认远程分支 Git中允许设置指定分支的默认推送远程仓库分支，设置需要使用以下命令： git branch -u \u003cremote_alias\u003e/\u003cremote_branch\u003e 注意，此时必须使用远程仓库链接的别名remote_alias，同时在设置前，应当先将remote_alias/remote_branch分支fetch到本地。 因此，使用git branch命令为当前分支设置默认push远程分支时，更为完整的流程应当如下： git remote add \u003cremote_alias\u003e \u003cremote\u003e git fetch \u003cremote_alias\u003e \u003cremote_branch\u003e git branch -u \u003cremote_alias\u003e/\u003cremote_branch\u003e 事实上，git branch命令还可用于设置任意分支在push时使用的默认远程分支。 此时，需要为git branch -u提供第二个参数。该参数在不提供的情况下，默认值为HEAD，HEAD即当前分支： git branch -u \u003cremote_alias\u003e/\u003cremote_branch\u003e [local_branch | HEAD] 一种设置默认push分支更为惯用的方式，是在push时添加-u选项，该选项会在push命令执行前，将当前远程仓库链接与分支设置为当前使用的本地仓库分支的默认push分支： git push -u \u003cremote_alias\u003e [\u003clocal_branch\u003e | HEAD:]\u003cremote_branch\u003e 以上命令等同于将local_branch或HEAD分支与远程仓库分支remote_alias/remote_branch进行了一对一的绑定，等同于此前git branch操作的集合。 该命令结束，此后在local_branch或HEAD分支的每次git push操作都可以不添加人任何参数，Git会自动选取绑定好的remote_alias与remote_branch作为默认参数。 ","date":"2019-09-21","objectID":"/posts/git/:10:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git分支 Git分支branch，是用来标记特定代码的提交，每一个分支通过SHA1SUM值来标识，所以对分支的操作是轻量级的，你改变的仅仅是SHA1SUM值。在多人协作的项目中，分支的作用尤为重要。 ","date":"2019-09-21","objectID":"/posts/git/:11:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.本地分支 要了解branch的基本操作，首先需要在本地初始化一个仓库，命令如下： git init Git Bash\"\rGit Bash\r 本地仓库初始化完毕之后，就可以开始对分支进行操作了。 Tip\r\r除了自行初始化仓库之外，你还可以选择克隆仓库。但对于克隆的仓库来说，该仓库可能是已经进行过提交的仓库，那么此时可以直接使用命令查看分支列表，或新建其他的分支。\r\r 🌟1|a.分支列表 Git Bash中可以看到，伴随着Git仓库的初始化，有一个默认的分支master已经被创建了出来。 使用查看分支列表的命令，查看当前Git仓库中的所有分支列表： git branch Git Bash\"\rGit Bash\r 该命令显示当前Git仓库中不存在任何的分支。为什么呢？ Git中规定，如果当前仓库未进行任何commit操作，则当前分支master不会被真实地创建，此时也无法新建其他的分支。 只有在master分支进行了一次commit操作后，才可以在分支列表看到该分支，此时新建分支操作才会被允许。 尝试创建一个新文件，并提交到本地，随后再次查看当前仓库的分支列表： touch file.txt git add . \u0026\u0026 git commit -m 'update.' git branch Git Bash\"\rGit Bash\r 命令运行后，master分支出现在了分支列表中。 Tip\r\r查看Git仓库分支除上述命令外，你还可以使用以下命令中的一条： git branch -l git branch --list \r\r 🌟1|b.新建分支 使用以下命令新建一个指定branch_name的新分支，同时使用命令显示当前目录的分支列表： git branch \u003cbranch_name\u003e git branch Git Bash\"\rGit Bash\r 可以看到，分支列表中多了一个名为main的分支。注意，分支列表中master分支被高亮显示，同时该分支前使用了*号进行标记，这表示了当前所处的分支是master分支。 Warning\r\r如果当前仓库未进行任何的提交，新建分支的操作是不被允许的。\r\r 🌟1|c.分支切换 分支切换使用的命令是checkout，因此也被叫做检出。 使用以下命令，可以切换当前所在的分支到main分支中，同时使用命令显示当前目录的分支列表： git checkout \u003cbranch_name\u003e git branch Git Bash\"\rGit Bash\r 显然，当前所在分支已经成功从master切换为main了。 实际上，checkout命令做了两件事情： 将HEAD指向指定的分支； 将工作目录恢复成指定分支所指向的快照内容。 因此，具体的分支切换可以分为两种情况： 从一个分支切换到另一个分支，此时分支的HEAD指向不一致； 从一个分支切换到另一个分支，此时分支的HEAD其指向一致。 情况一是最基本的分支切换情况。如果两个分支当前所指向的提交不一致，那么在进行切换时，必须要保证对任意文件的新建、删除、修改或暂存等操作已经进行了提交，否则强制切换分支会导致数据的丢失。 情况二则是比较特殊的情况，严格来说此时HEAD的指向并没有改变，因此Git不会将工作目录恢复成执行分支指向的快照内容。 假设此时有main、master分支，其指向同一个提交c6c162，如下： Git Bash\"\rGit Bash\r 在不进行任何提交的情况下，此时两个分支表现为共享工作目录、暂存区。 任意分支中进行的新建、删除、修改或暂存文件等操作，都同于另一个分支进行了同样的操作： Git Bash\"\rGit Bash\r 此时，任意一个分支的提交，都会造成当前分支HEAD的移动。 当HEAD发生了移动，两个分支不再指向同一提交，此后的分支切换便等同于普通的分支切换，即情况一： Git Bash\"\rGit Bash\r 以上案例来说，如果修改发生在main分支，但提交发生在master分支，那么main分支的修改数据等同于丢失。 因此严格来说，情况二也存在所谓的数据丢失的情况。 总结，分支切换前最重要的一点，是需要保证当前分支的整洁干净。所有未提交的工作，在分支切换后都存在丢失的可能性。 Tip\r\r当切换分支需要改变HEAD指向，同时当前分支具有未提交数据时，Git会阻止分支切换的操作。 可以使用以下命令，强制进行分支切换： git checkout -f \u003cbranch_name\u003e \r\r 🌟1|d.删除分支 删除分支十分简单，使用以下命令即可，同时使用命令显示当前目录的分支列表： git branch -d \u003cbranch_name\u003e git branch Git Bash\"\rGit Bash\r 有时候出于各种原因，无法对本地分支进行删除操作，此时可以使用以下命令中的一条，对分支进行强制删除： git branch -D \u003cbranch_name\u003e git branch -df \u003cbranch_name\u003e 最后，Git无法在当前所处于的分支中，删除当前所处于的分支。 ","date":"2019-09-21","objectID":"/posts/git/:11:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.远程分支 远程分支，实际上是使用fetch命令，拉取到本地的特殊分支。 git branch命令在没有任何参数时，只能显示本地分支列表。但你可以使用以下命令，用于显示当前的远程分支列表： git branch -r 也可以使用以下命令，显示当前的本地分支与远程分支的列表： git branch -a Git Bash\"\rGit Bash\r 拉取到本地的远程分支，完成可以当做本地分支来对待。 Tip\r\r了解了fetch的作用之后，会更加理解本地分支间的合并与远程仓库分支合并到本地的实质是一样的。 本地分支间的合并，就是普通的分支合并；而pull代码，实际就是将远程仓库分支fetch到本地成为一个特殊的本地分支，之后再使用merge与指定的本地分支进行合并，仅此而已。 分支合并一旦产生冲突，都是需要手动解决并填写注释信息的，没有例外。 \r\r ","date":"2019-09-21","objectID":"/posts/git/:11:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"3.分支合并 分支合并，可以理解为整合祖先同源分支的工作。对于非同源分支，事实上大多数情况下，并没有合并的需要。 如下图所示，有两个分支： master \u0026 dev\"\rmaster \u0026 dev\r master分支，其中A、C、E属于该分支； dev分支，其中A、B、D、F属于该分支。 其中，master分支和dev分支的HEAD指针，分别指向E和F。 对上述分支进行以下操作： git checkout master git merge dev 以上命令，Git将切换到master分支中，并将dev分支合并到当前分支master中，合并完成后如下所示： master \u0026 dev\"\rmaster \u0026 dev\r 现在，A、B、C、D、E、F、G都属于master节点，G是一次合并后的最终结果，是将E和F的代码合并后的结果。 Tip\r\r分支合并有可能会产生代码冲突，需要手动解决。例如，B和C都对A中已有的一段代码进行了不同的修改，那么在进行最终合并时，就有可能会产生冲突。\r\r 分支dev中的代码合并到master中，仍然可以继续在dev的分支上进行开发。 因为分支合并发生在master分支，此时仅仅是master分支的HEAD发生了变化，dev分支仍然存在且HEAD没有变化： master \u0026 dev\"\rmaster \u0026 dev\r ","date":"2019-09-21","objectID":"/posts/git/:11:3","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"4.合并冲突 分支的合并，往往会产生冲突，该冲突出现在分支比较之下，无法确定同一文件的最终修改内容的情况下。 例如，有两个分支main与master，它们都从同一个分支开始自己的历史，分支内最初拥有一个new.txt的空文件： Git Bash\"\rGit Bash\r 可以看到，分支main、master的HEAD均指向同一个提交。 此时，各自在main、master分支中，对new.txt进行不同的修改并提交，如下： git checkout main \u0026\u0026 echo \"main\" \u003e\u003e new.txt \u0026\u0026 git commit -a -m \"update in main.\" git checkout master \u0026\u0026 echo \"master\" \u003e\u003e new.txt \u0026\u0026 git commit -a -m \"update in master\" Git Bash\"\rGit Bash\r 通过在不同分支内查看文件内容，明显文件在各分支内已经拥有了不同版本的修改。 如果现在切换到master分支，并调用分支合并命令，将main分支合并到master分支中，会发生什么呢？ git checkout master git merge main Git Bash\"\rGit Bash\r 分支合并命令出现了冲突CONFLICT，此时进入了一个特殊分支master|MERGING内，表示出现了合并冲突。 合并出现冲突，明显是因为main、master分支，自new.txt文件为空的版本开始，各自修改并提交了该文件。导致最终合并时，Git无法得知应该保留main分支修改的版本，还是master分支修改的版本。 在分支master|MERGING下查看new.txt文件内容，如下： Git Bash\"\rGit Bash\r 可以发现，文件内容中既包含了HEAD分支即当前master分支的修改版本，也包含了main分支的修改版本，且修改的内容使用了多个=进行分割。 处理分支合并冲突的方法，就是手动确认出现冲突的文件，其应该保留的修改是什么。简而言之，手动修改冲突文件至你想要在当前分支保留的版本。 因此，现在需要手动确认new.txt中的实际保留部分是什么。编辑new.txt文件，并保留main分支的修改，如下： Git Bash\"\rGit Bash\r 确认完成对冲突文件的修改后，只需要再次将该文件添加到暂存区并提交，即可解决合并冲突，完成分支合并操作： Git Bash\"\rGit Bash\r 此时，分支也从master|MERGING回到了master。 ","date":"2019-09-21","objectID":"/posts/git/:11:4","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git凭证 如果希望从本地仓库将数据push到远程仓库，需要提供对应的认证凭证。认证凭证根据本地与远程仓库之间的连接协议的不同，而有所不同。 如果你使用的是SSH方式连接远端，并且设置了一个没有口令的密钥，这样就可以在不输入用户名和密码的情况下安全地传输数据。然而，这对http(s)协议来说是不可能的。 ","date":"2019-09-21","objectID":"/posts/git/:12:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"1.HTTP(s)协议连接 对于http(s)协议来说，它的每一个连接都是需要用户名密码验证。这在使用双重认证的情况下会更麻烦，因为你需要输入一个随机生成并且毫无规律的token作为密码。 幸运的是，Git拥有一个凭证系统来处理这个事情。下面有一些Git的选项： 默认所有都不缓存。每一次连接都会询问你的用户名和密码； cache模式会将凭证存放在内存中一段时间。密码永远不会被存储在磁盘中，并且在15分钟后从内存中清除； store模式会将凭证用明文的形式存放在磁盘中，并且永不过期。 这意味着除非你修改了你在Git服务器上的密码，否则你永远不需要再次输入你的凭证信息。这种方式的缺点是你的密码是用明文的方式存放在你的home目录下； 如果你使用的是Mac，Git还有一种osxkeychain模式，它会将凭证缓存到你系统用户的钥匙串中。这种方式将凭证存放在磁盘中，并且永不过期，但是是被加密的，这种加密方式与存放https凭证以及Safari的自动填写是相同的； 如果你使用的是Windows，你可以安装一个叫做Git Credential Manager for Windows的辅助工具。这和上面说的osxkeychain十分类似，但是是使用Windows Credential Store来控制敏感信息。 Tip\r\r如果你使用的是Windows系统，那往往在安装Git程序时，Git会询问你是否需要安装Git Credential Manager，此时勾选该项即可完成安装，毋需自行下载安装。 注意，在Git for Window 2.29或更高版本的安装中，其安装过程将会询问你是否需要安装Git Credential Manager Core，并同时将Git Credential Manager标记为deprecated。 GCM快速下载：Git Credential Manager for Windows GCM Core快速下载，及GCM Core与GCM的差别：Git Credential Manager Core \r\r 快速查看当前Git使用的凭证系统模式，使用以下命令： git config credential.helper Default Credential.hepler\r\r在Windows系统下，如果安装Git的过程中一并选择安装了GCM Core或GCM，那么credential.helper所对应的模式将会是manager-core或manager。 该credential.helper的配置实际存在于Git的系统配置中，可以在系统配置的文件中，查看对应credential.helper配置的信息： git config --system -l 也可以直接查询系统配置中credential.helper值： git config --system credential.helper \r\r 快速设置当前Git使用的凭证系统模式，使用以下命令： git config --system credential.helper \u003ccredential_mode\u003e 快速移除当前Git使用的凭证系统模式，使用以下命令： git config --system --unset credential.helper Git Configuration File\r\r命令git config中的首位参数，用于指定编辑或查看的配置文件，以Windows系统为例，该配置文件存在五种形式： --global：使用全局配置文件，默认不存在全局配置文件，只有手动配置时会新增该配置文件； --system：使用系统配置文件，默认使用的配置文件，所有默认的配置都存在于该配置文件中； --local：使用本地仓库配置文件，随着仓库的克隆或初始化而存在的配置文件； --worktree：使用每个工作树的配置文件，不常用； --file \u003cfile\u003e, -f：使用指定的配置文件，不常用。 其中，配置文件中配置的生效优先级是从小到大的。 例如，global和local中均配置了credential.helper，前者为cache模式，后者为store模式。 此时生效的配置是local，因为local的优先级大于global。 \r\r 对于一些需要针对系统所有本地仓库的配置，可以将配置新增在global全局配置或system系统配置中，如用户名、邮箱等；对于一些本地仓库的私有配置，可以将配置新增在local本地仓库配置中，如http代理。 使用GitHub仓库作为例子，将在不使用任何凭证系统的情况下，以测试使用http(s)协议连接时，输入用户名和密码的情况。 使用以下命令清空所有凭证系统配置： git config --global --unset credential.helper git config --system --unset credential.helper git config --local --unset credential.helper 此时，本地仓库使用的将会是默认的策略，即每一次连接都会询问连接的用户名和密码。 有以下GitHub远程仓库： GitHub Repo\"\rGitHub Repo\r 该仓库对应的http(s)协议连接地址为： https://github.com/2phangx-dylan/example.repository.git 初始化本地仓库，假设当前分支为main，使用以下命令拉取该仓库的数据： git pull https://github.com/2phangx-dylan/example.repository.git main Fatal: unable to access\r\r从GitHub中获取某些数据时，总是不会十分顺利，可能出现以下错误： OpenSSL SSL_connect: Connection was reset in connection to github.com:443引起该错误是因为网络连接不通所导致的。此时，需要添加代理服务器，以顺利访问github.com。 使用以下命令添加代理服务器信息到本地仓库的配置文件中： git config --local http.proxy http://\u003cproxy_ip\u003e:\u003cport\u003e \r\r Default Branch Name\r\rGit默认情况下，初始化仓库的默认分支是master，使用以下命令，可以改变初始化时的默认分支名为main： git config --system init.defaultbranch main \r\r 拉取数据成功后，不作更改，使用以下命令将数据推送到远程仓库： git push https://github.com/2phangx-dylan/example.repository.git main Windows系统下，会顺序出现以下对话框，要求你输入对应的用户名、密码： username\"\rusername\r password\"\rpassword\r 信息验证成功后，数据即可推送到远程仓库。 Tip\r\r出现OpenSSH对话框时，如果点击Cancel取消按钮，则此时窗口关闭，但Git Bash中会出现等待信息输入的命令行。 简而言之，你要么选择在OpenSSH对话框中键入必要信息，要么就在取消对话框后，回到Git Bash界面中键入必要信息。 \r\r 最后，对于具备二级验证的GitHub来说，连接远程仓库时，所提供的密码需要在设置中生成： personal access tokens\"\rpersonal access tokens\r 创建个人访问令牌时，Note等同于标题，Select Scopes根据需求勾选。对于简单的push命令，仅勾选public_repo域： personal access tokens\"\rpersonal access tokens\r 成功创建后，务必复制令牌到剪切板另作保存。 ","date":"2019-09-21","objectID":"/posts/git/:12:1","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"2.SSH协议连接 对于SSH协议的连接来说，由于其不支持匿名访问，因此不管是push，还是clone、pull/fetch，都需要验证本地私钥。 SSH连接看起来是这样的： ssh://[user@]server/project.git它可以简写为scp式： [user@]server:project.git 大多数情况下，获取到的SSH连接都是scp式链接。 相较于http(s)协议，使用SSH协议较为简单。只需要保证远程仓库所在平台拥有SSH公钥，同时本地目录拥有对应的SSH私钥，即可匹配连接。 使用SSH协议连接，有以下三个步骤： 生成SSH密钥对； 将公钥上传至远程仓库所在的平台； 将私钥保存至指定的本地目录中。 🌟2|a.生成SSH密钥对 Git中自带了ssh-keygen命令用于生成SSH密钥对，如下： ssh-keygen 生成密钥对会出现以下选项，可以自行选择填写： \u003e Enter a file in which to save the key (/c/Users/user/.ssh/id_rsa):[Press enter] \u003e Enter passphrase (empty for no passphrase): [Type a passphrase] \u003e Enter same passphrase again: [Type passphrase again] 注意，passphrase是用来保护你的私钥的密码，如果设置了passphrase，则每次使用私钥时都会要求你输入这个密码。 一般情况下passphrase不进行设置，更改passphrase可以使用以下命令： ssh-keygen -f \u003cprivate_key_file\u003e -P passphrase ssh-keygen命令中，部分选项如下： -t: 指定密钥的加密类型 -b: 指定密钥长度，默认长度为3072bits -f: 指定输出或输入文件 -C: 添加注释，默认注释是user@host -N: 指定新的passphrase 推荐使用以下命令，一步创建SSH密钥对： ssh-keygen -t rsa -b 4096 -f ~/.ssh/\u003cfile_name\u003e -C \u003cfile_name\u003e -N \"\" SSH密钥对将默认被存放在~/.ssh/路径下，此时passphrase为空，comment与文件同名。 GitHub在添加SSH公钥时，comment将会被默认识别为公钥的Title。 Tip\r\rWindows系统下的Home目录，如果无法清楚知道，可以在Git Bash中使用以下命令，打印Home目录路径： cd ~ \u0026\u0026 pwd \u0026\u0026 cd $OLDPWD \r\r 默认存放密钥对的路径之所以为~/.ssh/，是因为在使用SSH进行连接时，Git默认会在该路径下自动寻找相匹配的SSH私钥。 🌟2|b.GitHub中关联SSH公钥 使用以下命令生产密钥对： ssh-keygen -f ~/.ssh/some -C some -N \"\" 命令结束，默认输出目录~/.ssh/中，私钥和公钥已生成： ssh keygen\"\rssh keygen\r 公钥以.pub为后缀。在GitHub的设置中，添加该公钥即可： public key\"\rpublic key\r public key\"\rpublic key\r public key\"\rpublic key\r 🌟2|c.将SSH私钥添加到ssh-agent ssh-agent是管理私钥的工具，Git在使用SSH连接时，会使用已添加到ssh-agent中的私钥进行匹配认证。 使用以下命令，进入ssh-agent工具： ssh-agent bash 将生成的私钥添加到ssh-agent中，使用以下命令： ssh-add ~/.ssh/some 查看所有ssh-agent管理的私钥，使用以下命令： ssh-add -l 将私钥从ssh-agent中移除，使用以下命令： ssh-add -d ~/.ssh/some 移除所有ssh-agent中管理的私钥，使用以下命令： ssh-add -D 退出ssh-agent，使用以下命令： exit Tip\r\r如果不希望通过ssh-agent的方式管理私钥，可以自定义指定Host的验证私钥，后续的2|e小节中将有介绍。\r\r 🌟2|d.测试SSH连接 所有配置完成后，可以使用以下命令测试SSH连接是否成功： ssh -T git@github.com 首次进行连接时，ssh会询问你是否允许将当前访问的主机公钥记录在~/.ssh/known_hosts中。在下次访问相同主机时，OpenSSH会核对公钥信息。如果公钥不同，OpenSSH会发出警告，避免你受到DNS Hijack之类的攻击。 测试如果通过，会出现以下提示： Hi 2phangx-dylan! You've successfully authenticated, but GitHub does not provide shell access.如果测试无法通过，请检查你的步骤是否正确。 🌟2|e.自定义SSH私钥配置文件 如果你不希望将私钥交由ssh-agent进行管理，可以通过自定义配置的方式，将私钥关联到指定的ssh连接中。 在目录~/.ssh/下，新建config文件，内容如下： HostName github.comIdentityFile C:/Users/siyan/.ssh/some该文件中将指定主机名称HostName和身份文件IdentityFile的详细信息。此时，SSH连接中一旦检测到与HostName一致的同名Server，则都会使用该HostName下配置的IdentityFile用于验证。 以上配置的实际意义，是使用同一个私钥来验证所有来自github.com的SSH连接。 该文件中还支持配置SSH连接中Server的别名，其键名为Host。 Host wow.comHostName github.comIdentityFile C:/Users/siyan/.ssh/some举个例子，假如现在需要连接以下仓库： git@github.com:2phangx-dylan/example.repository.git 如果希望成功从远程仓库中拉取或推送数据，则必须使用config配置文件中的别名来取代真实连接中的服务器地址，此时拉取或推送数据的命令需要改写为： git pull git@wow.com:2phangx-dylan/example.repository.git main git push git@wow.com:2phangx-dylan/example.repository.git HEAD:main 从别名的使用不难知道config配置文件可以用于简化ssh连接的书写。除了服务器别名之外，config文件还可以配置默认的User数据。假如有以下配置： Host zUser gitHostName github.comIdentityFile C:/Users/siyan/.ssh/some此时，可以直接使用以下命令进行数据的拉取或推送： git pull z:2phangx-dylan/example.repository.git main git push z:2phangx-dylan/example.repository.git HEAD:main SSH连接中的z会被替换成github.com，同时由于没有指定的User，因此默认User会被自动设置为git。 ","date":"2019-09-21","objectID":"/posts/git/:12:2","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"Git忽略文件规则 一般我们总会有些无法纳入Git的管理，也不希望它们总是出现在未跟踪文件列表。通常都是些自动生成的文件，比如日志文件，或编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为.gitignore的文件，列出要忽略的文件的模式，如下： *.[oa] *~ 第一行告诉Git忽略所有以.o或.a结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉Git忽略所有名字以波浪符~结尾的文件，许多文本编辑软件如Emacs都使用这样的文件名保存副本。 此外你可能还需要忽略log、tmp或者pid目录，以及自动生成的文档等等。要养成一开始就为你的新仓库设置好.gitignore文件的习惯，以免将来误提交这类无用的文件。 文件.gitignore的格式规范如下： 所有空行或者以#开头的行都会被Git忽略； 可以使用标准的glob模式匹配，它会递归地应用到整个工作区中； 匹配模式可以以/开头返回值递归； 匹配模式可以以/结尾指定目录； 要忽略指定模式以外的文件或目录，可以在模式前加上叹号!取反。 所谓的glob模式是指shell所使用的简化了的正则表达式。 星号*匹配零个或多个任意字符； [abc]匹配任何一个列在方括号中的字符； 问号?只匹配一个任意字符； 如果在方括号中使用短划线风格两个字符，表示所有在这两个字符范围内的都可以匹配，如[0-9]表示匹配所有0~9之间的数字； 使用两个星号**表示匹配任意中间目录。如a//z可以匹配a/z、a/b/z或a/b/c/z等。 以下为简单例子： # 忽略所有.a文件 *.a # 跟踪所有的lib.a，即便你在前面忽略了.a文件 !lib.a # 只忽略当前目录下的TODO文件，而不忽略subdir/TODO /TODO # 忽略任何目录下名为build的文件夹 build/ # 忽略doc/notes.txt，但不忽略doc/server/arch.txt doc/*.txt # 忽略doc/目录及其所有子目录下的.pdf文件 doc/**/*.pdf--- ","date":"2019-09-21","objectID":"/posts/git/:13:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"资料参阅 详细关于Git的书籍，请参阅：Git - Book ","date":"2019-09-21","objectID":"/posts/git/:14:0","tags":["Git"],"title":"Git Tutorial","uri":"/posts/git/"},{"categories":["Java"],"content":"什么是加密？ 加密是使用特殊的方式将数据资料进行编码，使得非法用户即时取得该加密信息，也无法获取真正的资料内容。因此数据加密可以保护数据，防止监听攻击等。其重点在于数据的安全性。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:1:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"},{"categories":["Java"],"content":"什么是认证？ 身份认证是用来判断某个身份的真实性，确认身份后，系统才可以依照不同的身份，给予不同的权限。目的在于鉴别用户的真实性。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:2:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"},{"categories":["Java"],"content":"公钥与私钥 在现代密码体系中，加密和解密是采用不同的密钥分别进行的，也就是俗称的非对称密钥密码系统，每个通信方均需要两个密钥，即公钥与私钥，这两把密钥可以互为加解密。 公钥是公开的，不需要保密； 私钥是由个人持有的，必须妥善保管与保密。 公钥与私钥的原则： 一个公钥对应一个私钥； 密钥对中，让大家都知道的是公钥；不能公开的、只有自己知道的是私钥； 如果用其中一个密钥对数据进行加密处理，则必定只有对应的另一个密钥才能对数据进行解密处理； 如果用其中一个密钥可以对数据进行解密，则该数据必然是对应着另一个密钥所进行加密的。 非对称密钥密码的主要应用，就是公钥加密和公钥认证，而公钥加密的过程和公钥认证的过程是不一样的。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:3:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"},{"categories":["Java"],"content":"基于公钥的加密过程 假如有两个用户Alice和Bob，Alice需要把一段明文，通过双钥加密技术发送给Bob，Bob有一对公钥和私钥，那么加密、解密的过程如下： Bob将他的公钥传送给Alice； Alice使用Bob的公钥加密她的消息，并传送给Bob； Bob使用他的私钥解密Alice的消息。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:4:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"},{"categories":["Java"],"content":"基于公钥的认证过程 认证的过程不同于加密，主要用于鉴别用户的真伪。只需要鉴别一个用户的私钥是正确的，就可以鉴别这个用户的真伪。 假如仍然有两个用户Alice和Bob，Alice需要让Bob知道自己是Alice，而不是假冒的。 因此Alice需要使用自己的私钥对文件进行签名，并发送给Bob，Bob使用Alice的公钥对文件进行解密，如果解密成功，则证明Alice的私钥是正确的，从而完成了对Alice的身份认证。认证过程如下： Alice使用私钥对文件进行加密，从而对文件进行签名； Alice将签名的文件传送给Bob； Bob使用Alice的公钥解密文件，从而验证签名。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:5:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"},{"categories":["Java"],"content":"Git中的SSH连接 众所周知，Git中可以使用http(s)或SSH协议进行远程仓库的连接。其中SSH协议的连接，就要求远程仓库所在的平台，具备对应的SSH公钥，方便连接时使用本地的私钥进行验证。 在Git中可以使用以下命令，创建SSH连接公钥和私钥： ssh-keygen 该命令会在Git中的~/.ssh目录下生成两个文件id_dsa、id_dsa.pub，其分别为私钥和公钥。 Tip\r\rWindows系统下的Home目录，如果无法清楚知道，可以在Git Bash中使用以下命令，打印Home目录路径： cd ~ \u0026\u0026 pwd \u0026\u0026 cd $OLDPWD \r\r 在GitHub或Gitee中可以添加SSH公钥，用户可以使用私钥对文件进行签名，进而将文件传送到服务器进行认证；服务器也可以使用你的公钥对数据进行加密传输到用户的设备上，用户可以使用私钥对加密数据进行解密。 ","date":"2019-09-20","objectID":"/posts/ssh_publicprivate_key/:6:0","tags":["Security"],"title":"SSH Public \u0026 Private Key","uri":"/posts/ssh_publicprivate_key/"}]